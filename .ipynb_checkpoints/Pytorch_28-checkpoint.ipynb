{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.5.1\n",
      "0.6.1\n",
      "epoch: 0 total_correct: 47887 loss: 323.2239801287651\n",
      "epoch: 1 total_correct: 51662 loss: 224.02470494806767\n",
      "epoch: 2 total_correct: 52252 loss: 207.23289933800697\n",
      "epoch: 3 total_correct: 52617 loss: 195.93179236352444\n",
      "epoch: 4 total_correct: 52833 loss: 191.66520643234253\n",
      "0.88055\n",
      "torch.Size([60000, 10])\n",
      "False\n",
      "None\n",
      "None\n",
      "total correct: 52196\n",
      "accuracy: 0.8699333333333333\n"
     ]
    }
   ],
   "source": [
    "# imports\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "torch.set_printoptions(linewidth=120)\n",
    "torch.set_grad_enabled(True)\n",
    "\n",
    "print(torch.__version__)\n",
    "print(torchvision.__version__)\n",
    "\n",
    "train_set = torchvision.datasets.FashionMNIST(\n",
    "    root='./data/FashionMNIST', train=True, download=True, transform=transforms.Compose([transforms.ToTensor()\n",
    "                                                                                         ])\n",
    ")\n",
    "\n",
    "# class definition\n",
    "\n",
    "\n",
    "def get_num_correct(preds, labels):\n",
    "    return preds.argmax(dim=1).eq(labels).sum().item()\n",
    "\n",
    "\n",
    "class Network(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=6, kernel_size=5)\n",
    "        self.conv2 = nn.Conv2d(in_channels=6, out_channels=12, kernel_size=5)\n",
    "\n",
    "        self.fc1 = nn.Linear(in_features=12*4*4, out_features=120)\n",
    "        self.fc2 = nn.Linear(in_features=120, out_features=60)\n",
    "        self.out = nn.Linear(in_features=60, out_features=10)\n",
    "\n",
    "    def forward(self, t):\n",
    "        # (1) input layer\n",
    "        t = t\n",
    "\n",
    "        # (2) hidden conv layer\n",
    "        t = self.conv1(t)\n",
    "        t = F.relu(t)\n",
    "        t = F.max_pool2d(t, kernel_size=2, stride=2)\n",
    "\n",
    "        # (3) hidden conv layer\n",
    "        t = self.conv2(t)\n",
    "        t = F.relu(t)\n",
    "        t = F.max_pool2d(t, kernel_size=2, stride=2)\n",
    "\n",
    "        # (4) hidden linear layer\n",
    "        t = t.reshape(-1, 12*4*4)\n",
    "        t = self.fc1(t)\n",
    "        t = F.relu(t)\n",
    "\n",
    "        # (5) hidden linear layer\n",
    "        t = self.fc2(t)\n",
    "        t = F.relu(t)\n",
    "\n",
    "        # (6) output layer\n",
    "        t = self.out(t)\n",
    "        #t = F.softmax(t,dim=1)\n",
    "\n",
    "        return t\n",
    "\n",
    "def get_all_preds(model,loader):\n",
    "    all_preds = torch.tensor([])    #create tensor to store all predictions in\n",
    "    for batch in loader:    #iterate per batch\n",
    "        images, labels = batch  #take out images and labels\n",
    "\n",
    "    #version 1.1\n",
    "        preds = model(images)   #run the images in this batch through the model, create predictions\n",
    "        all_preds = torch.cat(  #concatenate these predictions to the all_preds tensor\n",
    "            (all_preds, preds)\n",
    "            ,dim=0\n",
    "    )\n",
    " \n",
    "    #version 1.2 \n",
    "    #     with torch.no_grad():\n",
    "\n",
    "    #         preds = model(images)   #run the images in this batch through the model, create predictions\n",
    "    #         all_preds = torch.cat(  #concatenate these predictions to the all_preds tensor\n",
    "    #             (all_preds, preds)\n",
    "    #             ,dim=0\n",
    "    #     )\n",
    "    return all_preds\n",
    "\n",
    "# computations first time to train\n",
    "network = Network()  # create network\n",
    "train_loader = torch.utils.data.DataLoader(train_set, batch_size=100)\n",
    "optimiser = optim.Adam(network.parameters(), lr=0.01)\n",
    "\n",
    "for epoch in range(5):\n",
    "\n",
    "    total_loss = 0\n",
    "    total_correct = 0\n",
    "\n",
    "    for batch in train_loader:  # get batch\n",
    "        images, labels = batch  # define images and labels\n",
    "\n",
    "        preds = network(images)  # create first predictions\n",
    "        loss = F.cross_entropy(preds, labels)  # calculate loss\n",
    "\n",
    "        optimiser.zero_grad()\n",
    "        loss.backward()  # calculate gradient\n",
    "        optimiser.step()  # update weights\n",
    "\n",
    "        total_loss += loss.item()\n",
    "        total_correct += get_num_correct(preds, labels)\n",
    "    \n",
    "    print(\"epoch:\", epoch, \"total_correct:\", total_correct, \"loss:\", total_loss)\n",
    "\n",
    "print(total_correct/len(train_set)) \n",
    "\n",
    "#second time to compute entire predictions unit, not training extra\n",
    "with torch.no_grad():   #version 2.1\n",
    "    prediction_loader = torch.utils.data.DataLoader(train_set, batch_size=10000) #the data loader\n",
    "    train_preds = get_all_preds(network,prediction_loader)\n",
    "\n",
    "#version 2.2\n",
    "# prediction_loader = torch.utils.data.DataLoader(train_set, batch_size=10000) #the data loader\n",
    "# with torch.no_grad():\n",
    "#     train_preds = get_all_preds(network,prediction_loader)\n",
    "\n",
    "#version 2.3\n",
    "# prediction_loader = torch.utils.data.DataLoader(train_set, batch_size=10000) #the data loader\n",
    "# train_preds = get_all_preds(network,prediction_loader)\n",
    "\n",
    "preds_correct = get_num_correct(train_preds,train_set.targets)\n",
    "\n",
    "print(train_preds.shape)\n",
    "print(train_preds.requires_grad)\n",
    "print(train_preds.grad)\n",
    "print(train_preds.grad_fn)\n",
    "\n",
    "print(\"total correct:\",preds_correct)\n",
    "print(\"accuracy:\", preds_correct/len(train_set))\n",
    "\n",
    "# with torch.no_grad():\n",
    "#     prediction_loader = torch.utils.data.DataLoader(train_set, batch_size=10000)\n",
    "#     train_preds = get_all_preds(network,prediction_loader)\n",
    "\n",
    "# print(train_preds.requires_grad)\n",
    "# print(train_preds.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Confusion matrix\n",
    "stacked = torch.stack(  #for each prediction, couple it to the label it was supposed to have\n",
    "    (\n",
    "        train_set.targets\n",
    "        ,train_preds.argmax(dim=1)  #why dim=1? Taking maximum value of this dimension, you have 60000x10, and the 10 should be maxed. Just make sure to keep paying attention to this\n",
    "    )\n",
    "    ,dim=1\n",
    ")\n",
    "\n",
    "cmt = torch.zeros(10,10,dtype=torch.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]], dtype=torch.int32)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cmt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[5499,    2,   41,  184,   14,    6,  228,    0,   26,    0],\n",
       "        [  28, 5679,    4,  259,    6,   10,   11,    1,    2,    0],\n",
       "        [ 111,    0, 3737,   70, 1560,    6,  496,    0,   20,    0],\n",
       "        [ 140,    2,   10, 5598,  195,    1,   52,    0,    2,    0],\n",
       "        [  20,    1,  144,  230, 5245,    0,  332,    0,   28,    0],\n",
       "        [   0,    0,    0,    0,    0, 5830,    0,  109,    5,   56],\n",
       "        [1476,    2,  451,  192,  640,    0, 3165,    0,   74,    0],\n",
       "        [   0,    0,    0,    0,    0,   57,    0, 5831,    3,  109],\n",
       "        [  24,    0,   15,   21,   15,   15,   30,   10, 5869,    1],\n",
       "        [   0,    0,    1,    1,    0,   26,    0,  226,    3, 5743]], dtype=torch.int32)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for p in stacked:\n",
    "    j, k = p.tolist()\n",
    "    cmt[j,k]=cmt[j,k]+1\n",
    "    \n",
    "cmt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'resources'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-9-b57e833f79ee>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mconfusion_matrix\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mresources\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplotcm\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mplot_confusion_matrix\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'resources'"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from resources.plotcm import plot_confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(train_set.targets,train_preds.argmax(dim=1))\n",
    "print(type(cm))\n",
    "cm"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
