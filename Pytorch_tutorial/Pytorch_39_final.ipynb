{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>run</th>\n",
       "      <th>epoch</th>\n",
       "      <th>loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>epoch duration</th>\n",
       "      <th>run duration</th>\n",
       "      <th>lr</th>\n",
       "      <th>batch_size</th>\n",
       "      <th>num_workers</th>\n",
       "      <th>device</th>\n",
       "      <th>trainset</th>\n",
       "      <th>network</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.009947</td>\n",
       "      <td>0.607117</td>\n",
       "      <td>7.767993</td>\n",
       "      <td>15.559691</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1000</td>\n",
       "      <td>1</td>\n",
       "      <td>cuda</td>\n",
       "      <td>not_normal</td>\n",
       "      <td>no_batch_norm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.573458</td>\n",
       "      <td>0.791500</td>\n",
       "      <td>6.749415</td>\n",
       "      <td>9.483103</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1000</td>\n",
       "      <td>1</td>\n",
       "      <td>cuda</td>\n",
       "      <td>not_normal</td>\n",
       "      <td>batch_norm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0.771618</td>\n",
       "      <td>0.744483</td>\n",
       "      <td>10.500875</td>\n",
       "      <td>12.625376</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1000</td>\n",
       "      <td>1</td>\n",
       "      <td>cuda</td>\n",
       "      <td>normal</td>\n",
       "      <td>no_batch_norm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0.391411</td>\n",
       "      <td>0.854550</td>\n",
       "      <td>10.039930</td>\n",
       "      <td>12.090030</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1000</td>\n",
       "      <td>1</td>\n",
       "      <td>cuda</td>\n",
       "      <td>normal</td>\n",
       "      <td>batch_norm</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   run  epoch      loss  accuracy  epoch duration  run duration    lr  \\\n",
       "0    1      1  1.009947  0.607117        7.767993     15.559691  0.01   \n",
       "1    2      1  0.573458  0.791500        6.749415      9.483103  0.01   \n",
       "2    3      1  0.771618  0.744483       10.500875     12.625376  0.01   \n",
       "3    4      1  0.391411  0.854550       10.039930     12.090030  0.01   \n",
       "\n",
       "   batch_size  num_workers device    trainset        network  \n",
       "0        1000            1   cuda  not_normal  no_batch_norm  \n",
       "1        1000            1   cuda  not_normal     batch_norm  \n",
       "2        1000            1   cuda      normal  no_batch_norm  \n",
       "3        1000            1   cuda      normal     batch_norm  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>run</th>\n",
       "      <th>epoch</th>\n",
       "      <th>loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>epoch duration</th>\n",
       "      <th>run duration</th>\n",
       "      <th>lr</th>\n",
       "      <th>batch_size</th>\n",
       "      <th>num_workers</th>\n",
       "      <th>device</th>\n",
       "      <th>trainset</th>\n",
       "      <th>network</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0.391411</td>\n",
       "      <td>0.854550</td>\n",
       "      <td>10.039930</td>\n",
       "      <td>12.090030</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1000</td>\n",
       "      <td>1</td>\n",
       "      <td>cuda</td>\n",
       "      <td>normal</td>\n",
       "      <td>batch_norm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.573458</td>\n",
       "      <td>0.791500</td>\n",
       "      <td>6.749415</td>\n",
       "      <td>9.483103</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1000</td>\n",
       "      <td>1</td>\n",
       "      <td>cuda</td>\n",
       "      <td>not_normal</td>\n",
       "      <td>batch_norm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0.771618</td>\n",
       "      <td>0.744483</td>\n",
       "      <td>10.500875</td>\n",
       "      <td>12.625376</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1000</td>\n",
       "      <td>1</td>\n",
       "      <td>cuda</td>\n",
       "      <td>normal</td>\n",
       "      <td>no_batch_norm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.009947</td>\n",
       "      <td>0.607117</td>\n",
       "      <td>7.767993</td>\n",
       "      <td>15.559691</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1000</td>\n",
       "      <td>1</td>\n",
       "      <td>cuda</td>\n",
       "      <td>not_normal</td>\n",
       "      <td>no_batch_norm</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   run  epoch      loss  accuracy  epoch duration  run duration    lr  \\\n",
       "3    4      1  0.391411  0.854550       10.039930     12.090030  0.01   \n",
       "1    2      1  0.573458  0.791500        6.749415      9.483103  0.01   \n",
       "2    3      1  0.771618  0.744483       10.500875     12.625376  0.01   \n",
       "0    1      1  1.009947  0.607117        7.767993     15.559691  0.01   \n",
       "\n",
       "   batch_size  num_workers device    trainset        network  \n",
       "3        1000            1   cuda      normal     batch_norm  \n",
       "1        1000            1   cuda  not_normal     batch_norm  \n",
       "2        1000            1   cuda      normal  no_batch_norm  \n",
       "0        1000            1   cuda  not_normal  no_batch_norm  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from IPython.display import display, clear_output\n",
    "import pandas as pd\n",
    "import time\n",
    "import json\n",
    "\n",
    "from itertools import product\n",
    "from collections import namedtuple\n",
    "from collections import OrderedDict\n",
    "\n",
    "import os \n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "#NameFile\n",
    "class NameFile():\n",
    "    @staticmethod#static? iets met dat je m kan callen using the class itself. don't need an instance of the class, to call the method. i guess dat je m dus niet eerst hoeft te initieren alszijnde type x? \n",
    "    def nameit(params): #ga er dus vanuit dat je alleen keys and values hebt, dus alleen 0 en 1 voor die ene index. wellicht gaat dit dus ooit mis, makkelijk te herstellen\n",
    "\n",
    "        items_hier = list(params.items()) #keys+values\n",
    "        num_k=0 #amount of keys present\n",
    "        comment = '' #the string for the filename\n",
    "        \n",
    "        #make the comment by looping over keys and values\n",
    "        for k in params.keys():\n",
    "            comment += f'{items_hier[num_k][0]}=' #add the key\n",
    "            for v in items_hier[num_k][1]:\n",
    "                comment +=(f'{v}_') #add the values\n",
    "            num_k+=1 #for indexing next loop to get next keys/values in list\n",
    "        comment+='results'\n",
    "        return comment\n",
    "\n",
    "#RunBuilder\n",
    "class RunBuilder():\n",
    "    @staticmethod#static? iets met dat je m kan callen using the class itself. don't need an instance of the class, to call the method. i guess dat je m dus niet eerst hoeft te initieren alszijnde type x? \n",
    "    def get_runs(params):\n",
    "        \n",
    "        Run = namedtuple('Run',params.keys())#die ordereddicttionary heeft keys and values. dit heb je wel eens eerder gezien I guess.\n",
    "                                             #blijkbaar maakt ie een mooie string als je die keys zo oproept. test dat even.\n",
    "        \n",
    "        runs = []\n",
    "        for v in product(*params.values()): #dit doet dus iets dat ie per value combo nieuwe iteratie doet\n",
    "            runs.append(Run(*v))\n",
    "            \n",
    "        return runs\n",
    "\n",
    "#RunManager\n",
    "class RunManager():\n",
    "    def __init__(self):\n",
    "        \n",
    "        self.epoch_count = 0\n",
    "        self.epoch_loss = 0\n",
    "        self.epoch_num_correct = 0\n",
    "        self.epoch_start_time = None\n",
    "        \n",
    "        self.run_params = None\n",
    "        self.run_count = 0\n",
    "        self.run_data = []\n",
    "        self.run_start_time = None\n",
    "        \n",
    "        self.network = None\n",
    "        self.loader = None\n",
    "        self.tb = None\n",
    "\n",
    "    def begin_run(self,run,network,loader): #die self is dus gewoon de variabel naam links van de streep\n",
    "        #start time for a run, parameters run added, run_count+1 (stays same for all epochs)\n",
    "        #network copied, loader copied, name given in tb. \n",
    "        self.run_start_time = time.time()\n",
    "        \n",
    "        self.run_params = run\n",
    "        self.run_count += 1\n",
    "        self.network = network\n",
    "        self.loader = loader\n",
    "        # self.tb = SummaryWriter() #no comment\n",
    "        self.tb = SummaryWriter(comment=f'-{run}')\n",
    "\n",
    "        \n",
    "        images,labels = next(iter(self.loader)) #misschien wel gewoon plaatjes inladen voor foto'tje in tensorboard\n",
    "        grid = torchvision.utils.make_grid(images)\n",
    "        \n",
    "        self.tb.add_image('images',grid)\n",
    "        self.tb.add_graph(\n",
    "            self.network\n",
    "            ,images.to(getattr(run,'device','cpu')))\n",
    "        \n",
    "    def end_run(self):\n",
    "        self.tb.close()\n",
    "        self.epoch_count = 0\n",
    "\n",
    "    def begin_epoch(self):\n",
    "        self.epoch_start_time = time.time()\n",
    "        \n",
    "        self.epoch_count += 1\n",
    "        self.epoch_loss = 0\n",
    "        self.epoch_num_correct = 0\n",
    "        \n",
    "    def end_epoch(self):\n",
    "        \n",
    "        epoch_duration = time.time()-self.epoch_start_time\n",
    "        run_duration = time.time()-self.run_start_time\n",
    "        \n",
    "        loss = self.epoch_loss/len(self.loader.dataset)\n",
    "        accuracy = self.epoch_num_correct/len(self.loader.dataset)\n",
    "        \n",
    "        self.tb.add_scalar('Loss',loss,self.epoch_count)\n",
    "        self.tb.add_scalar('Accuracy',accuracy,self.epoch_count)\n",
    "        \n",
    "        for name, param in self.network.named_parameters():\n",
    "            self.tb.add_histogram(name,param,self.epoch_count)\n",
    "            self.tb.add_histogram(f'{name}.grad',param.grad,self.epoch_count)\n",
    "            \n",
    "        results = OrderedDict()\n",
    "        results[\"run\"]=self.run_count\n",
    "        results[\"epoch\"]=self.epoch_count\n",
    "        results[\"loss\"]=loss\n",
    "        results[\"accuracy\"]=accuracy\n",
    "        results[\"epoch duration\"]=epoch_duration\n",
    "        results[\"run duration\"]=run_duration\n",
    "                            \n",
    "        for k,v in self.run_params._asdict().items():  #deze komen uit run, je batch_size & lr\n",
    "            results[k] = v #geloof dat je hier dus voor elke run met andere batch size etc. maar 1 lr en batchsize toevoegt, vandaar dat dit niet in de loop zit\n",
    "        self.run_data.append(results) #1 batch_size en lr bij de results bij, en vervolgens voeg je al je results toe aan wat je metadata i guess\n",
    "        df = pd.DataFrame.from_dict(self.run_data,orient='columns') #dit zorgt dat het in een leuk tabelletje staat\n",
    "                                \n",
    "        clear_output(wait=True)\n",
    "        display(df)\n",
    "                                \n",
    "    def track_loss(self,loss,batch):\n",
    "            self.epoch_loss += loss.item()* batch[0].shape[0]\n",
    "                                    \n",
    "    def track_num_correct(self,preds,labels):\n",
    "            self.epoch_num_correct += self._get_num_correct(preds,labels)\n",
    "        \n",
    "    @torch.no_grad()\n",
    "    def _get_num_correct(self,preds,labels):\n",
    "        return preds.argmax(dim=1).eq(labels).sum().item()\n",
    "    \n",
    "    def save(self,fileName,ResDir,file_num):\n",
    "        \n",
    "        os.mkdir(f'{ResDir}\\{file_num}')\n",
    "        \n",
    "        pd.DataFrame.from_dict(\n",
    "        self.run_data\n",
    "        ,orient = 'columns'\n",
    "        ).to_csv(f'{ResDir}\\{file_num}\\{fileName}.csv')\n",
    "        \n",
    "        with open(f'{ResDir}\\{file_num}\\{fileName}.json','w',encoding='utf-8') as f:\n",
    "            json.dump(self.run_data, f, ensure_ascii=False, indent=4)\n",
    "\n",
    "torch.manual_seed(50)\n",
    "network1 = nn.Sequential(\n",
    "    nn.Conv2d(in_channels=1, out_channels=6, kernel_size=5)\n",
    "    ,nn.ReLU()\n",
    "    ,nn.MaxPool2d(kernel_size=2,stride=2)\n",
    "    ,nn.Conv2d(in_channels=6, out_channels=12, kernel_size=5)\n",
    "    ,nn.ReLU()\n",
    "    ,nn.MaxPool2d(kernel_size=2,stride=2)\n",
    "    ,nn.Flatten(start_dim=1)\n",
    "    ,nn.Linear(in_features=12*4*4,out_features=120)\n",
    "    ,nn.ReLU()\n",
    "    ,nn.Linear(in_features=120,out_features=60)\n",
    "    ,nn.ReLU()\n",
    "    ,nn.Linear(in_features=60,out_features=10)   \n",
    ")\n",
    "\n",
    "torch.manual_seed(50)\n",
    "network2 = nn.Sequential(\n",
    "    nn.Conv2d(in_channels=1, out_channels=6, kernel_size=5)\n",
    "    ,nn.ReLU()\n",
    "    ,nn.MaxPool2d(kernel_size=2,stride=2)\n",
    "    ,nn.BatchNorm2d(6)\n",
    "    ,nn.Conv2d(in_channels=6, out_channels=12, kernel_size=5)\n",
    "    ,nn.ReLU()\n",
    "    ,nn.MaxPool2d(kernel_size=2,stride=2)\n",
    "    ,nn.Flatten(start_dim=1)\n",
    "    ,nn.Linear(in_features=12*4*4,out_features=120)\n",
    "    ,nn.ReLU()\n",
    "    ,nn.BatchNorm1d(120)\n",
    "    ,nn.Linear(in_features=120,out_features=60)\n",
    "    ,nn.ReLU()\n",
    "    ,nn.Linear(in_features=60,out_features=10)   \n",
    ")\n",
    "\n",
    "train_set = torchvision.datasets.FashionMNIST(\n",
    "root='./data'\n",
    "    ,download=True\n",
    "    ,train=True\n",
    "    ,transform=transforms.Compose([\n",
    "        transforms.ToTensor()\n",
    "    ])\n",
    ")\n",
    "\n",
    "\n",
    "loader = DataLoader(train_set,batch_size=len(train_set),num_workers=1)\n",
    "data=next(iter(loader))\n",
    "mean = data[0].mean()\n",
    "std = data[0].std()\n",
    "mean,std\n",
    "\n",
    "train_set_normal = torchvision.datasets.FashionMNIST(\n",
    "root='./data'\n",
    "    ,download=True\n",
    "    ,train=True\n",
    "    ,transform=transforms.Compose([\n",
    "        transforms.ToTensor()\n",
    "        ,transforms.Normalize(mean,std)\n",
    "    ])\n",
    ")\n",
    "\n",
    "\n",
    "trainsets = {\n",
    "    'not_normal': train_set\n",
    "    ,'normal':train_set_normal\n",
    "}\n",
    "\n",
    "networks = {\n",
    "    'no_batch_norm': network1\n",
    "    ,'batch_norm':network2\n",
    "}\n",
    "\n",
    "params = OrderedDict(\n",
    "    lr = [.01]\n",
    "    ,batch_size = [1000]\n",
    "    ,num_workers = [1]\n",
    "    ,device = ['cuda']\n",
    "    ,trainset = list(trainsets.keys())\n",
    "    ,network=list(networks.keys())\n",
    ")\n",
    "\n",
    "ResDir = 'runs_results'\n",
    "file_num = '1709_1047'\n",
    "m=RunManager()\n",
    "\n",
    "for run in RunBuilder.get_runs(params):\n",
    "    \n",
    "    device=torch.device(run.device)\n",
    "    network = networks[run.network].to(device)\n",
    "    loader = DataLoader(trainsets[run.trainset],batch_size=run.batch_size,num_workers=run.num_workers)\n",
    "    optimiser = optim.Adam(network.parameters(),lr=run.lr)\n",
    "    \n",
    "    m.begin_run(run,network,loader)\n",
    "    for epoch in range(1):\n",
    "        m.begin_epoch()\n",
    "        for batch in loader:\n",
    "            \n",
    "            images = batch[0].to(device)\n",
    "            labels = batch[1].to(device)\n",
    "            preds = network(images)\n",
    "            loss = F.cross_entropy(preds,labels)\n",
    "            optimiser.zero_grad()\n",
    "            loss.backward()\n",
    "            optimiser.step()\n",
    "            \n",
    "            m.track_loss(loss,batch)\n",
    "            m.track_num_correct(preds,labels)\n",
    "        m.end_epoch()\n",
    "    m.end_run()\n",
    "m.save(NameFile.nameit(params),ResDir,file_num) #mooie naam voor de results file met alle parameter values erin\n",
    "\n",
    "df = pd.DataFrame.from_dict(m.run_data,orient='columns').sort_values('accuracy',ascending=False) #dit zorgt dat het in een leuk tabelletje staat\n",
    "pd.set_option('display.max_rows',None)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
