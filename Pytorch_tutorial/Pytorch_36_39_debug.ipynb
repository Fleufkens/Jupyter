{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from IPython.display import display, clear_output\n",
    "import pandas as pd\n",
    "import time\n",
    "import json\n",
    "\n",
    "from itertools import product\n",
    "from collections import namedtuple\n",
    "from collections import OrderedDict\n",
    "\n",
    "import os \n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#NameFile\n",
    "class NameFile():\n",
    "    @staticmethod#static? iets met dat je m kan callen using the class itself. don't need an instance of the class, to call the method. i guess dat je m dus niet eerst hoeft te initieren alszijnde type x? \n",
    "    def nameit(params): #ga er dus vanuit dat je alleen keys and values hebt, dus alleen 0 en 1 voor die ene index. wellicht gaat dit dus ooit mis, makkelijk te herstellen\n",
    "\n",
    "        items_hier = list(params.items()) #keys+values\n",
    "        num_k=0 #amount of keys present\n",
    "        comment = '' #the string for the filename\n",
    "        \n",
    "        #make the comment by looping over keys and values\n",
    "        for k in params.keys():\n",
    "            comment += f'{items_hier[num_k][0]}=' #add the key\n",
    "            for v in items_hier[num_k][1]:\n",
    "                comment +=(f'{v}_') #add the values\n",
    "            num_k+=1 #for indexing next loop to get next keys/values in list\n",
    "        comment+='results'\n",
    "        return comment\n",
    "\n",
    "#RunBuilder\n",
    "class RunBuilder():\n",
    "    @staticmethod#static? iets met dat je m kan callen using the class itself. don't need an instance of the class, to call the method. i guess dat je m dus niet eerst hoeft te initieren alszijnde type x? \n",
    "    def get_runs(params):\n",
    "        \n",
    "        Run = namedtuple('Run',params.keys())#die ordereddicttionary heeft keys and values. dit heb je wel eens eerder gezien I guess.\n",
    "                                             #blijkbaar maakt ie een mooie string als je die keys zo oproept. test dat even.\n",
    "        \n",
    "        runs = []\n",
    "        for v in product(*params.values()): #dit doet dus iets dat ie per value combo nieuwe iteratie doet\n",
    "            runs.append(Run(*v))\n",
    "            \n",
    "        return runs\n",
    "\n",
    "#RunManager\n",
    "class RunManager():\n",
    "    def __init__(self):\n",
    "        \n",
    "        self.epoch_count = 0\n",
    "        self.epoch_loss = 0\n",
    "        self.epoch_num_correct = 0\n",
    "        self.epoch_start_time = None\n",
    "        \n",
    "        self.run_params = None\n",
    "        self.run_count = 0\n",
    "        self.run_data = []\n",
    "        self.run_start_time = None\n",
    "        \n",
    "        self.network = None\n",
    "        self.loader = None\n",
    "        self.tb = None\n",
    "\n",
    "    def begin_run(self,run,network,loader): #die self is dus gewoon de variabel naam links van de streep\n",
    "        #start time for a run, parameters run added, run_count+1 (stays same for all epochs)\n",
    "        #network copied, loader copied, name given in tb. \n",
    "        self.run_start_time = time.time()\n",
    "        \n",
    "        self.run_params = run\n",
    "        self.run_count += 1\n",
    "        self.network = network\n",
    "        self.loader = loader\n",
    "        self.tb = SummaryWriter(comment=f'-{run}')\n",
    "        \n",
    "        images,labels = next(iter(self.loader)) #misschien wel gewoon plaatjes inladen voor foto'tje in tensorboard\n",
    "        grid = torchvision.utils.make_grid(images)\n",
    "        \n",
    "        self.tb.add_image('images',grid)\n",
    "        self.tb.add_graph(\n",
    "            self.network\n",
    "            ,images.to(getattr(run,'device','cpu')))\n",
    "        \n",
    "    def end_run(self):\n",
    "        self.tb.close()\n",
    "        self.epoch_count = 0\n",
    "\n",
    "    def begin_epoch(self):\n",
    "        self.epoch_start_time = time.time()\n",
    "        \n",
    "        self.epoch_count += 1\n",
    "        self.epoch_loss = 0\n",
    "        self.epoch_num_correct = 0\n",
    "        \n",
    "    def end_epoch(self):\n",
    "        \n",
    "        epoch_duration = time.time()-self.epoch_start_time\n",
    "        run_duration = time.time()-self.run_start_time\n",
    "        \n",
    "        loss = self.epoch_loss/len(self.loader.dataset)\n",
    "        accuracy = self.epoch_num_correct/len(self.loader.dataset)\n",
    "        \n",
    "        self.tb.add_scalar('Loss',loss,self.epoch_count)\n",
    "        self.tb.add_scalar('Accuracy',accuracy,self.epoch_count)\n",
    "        \n",
    "        for name, param in self.network.named_parameters():\n",
    "            self.tb.add_histogram(name,param,self.epoch_count)\n",
    "            self.tb.add_histogram(f'{name}.grad',param.grad,self.epoch_count)\n",
    "            \n",
    "        results = OrderedDict()\n",
    "        results[\"run\"]=self.run_count\n",
    "        results[\"epoch\"]=self.epoch_count\n",
    "        results[\"loss\"]=loss\n",
    "        results[\"accuracy\"]=accuracy\n",
    "        results[\"epoch duration\"]=epoch_duration\n",
    "        results[\"run duration\"]=run_duration\n",
    "                            \n",
    "        for k,v in self.run_params._asdict().items():  #deze komen uit run, je batch_size & lr\n",
    "            results[k] = v #geloof dat je hier dus voor elke run met andere batch size etc. maar 1 lr en batchsize toevoegt, vandaar dat dit niet in de loop zit\n",
    "        self.run_data.append(results) #1 batch_size en lr bij de results bij, en vervolgens voeg je al je results toe aan wat je metadata i guess\n",
    "        df = pd.DataFrame.from_dict(self.run_data,orient='columns') #dit zorgt dat het in een leuk tabelletje staat\n",
    "                                \n",
    "        clear_output(wait=True)\n",
    "        display(df)\n",
    "                                \n",
    "    def track_loss(self,loss):\n",
    "            self.epoch_loss += loss.item()* self.loader.batch_size\n",
    "                                    \n",
    "    def track_num_correct(self,preds,labels):\n",
    "            self.epoch_num_correct += self._get_num_correct(preds,labels)\n",
    "        \n",
    "    @torch.no_grad()\n",
    "    def _get_num_correct(self,preds,labels):\n",
    "        return preds.argmax(dim=1).eq(labels).sum().item()\n",
    "    \n",
    "    def save(self,fileName,ResDir,file_num):\n",
    "        \n",
    "        os.mkdir(f'{ResDir}\\{file_num}')\n",
    "        \n",
    "        pd.DataFrame.from_dict(\n",
    "        self.run_data\n",
    "        ,orient = 'columns'\n",
    "        ).to_csv(f'{ResDir}\\{file_num}\\{fileName}.csv')\n",
    "        \n",
    "        with open(f'{ResDir}\\{file_num}\\{fileName}.json','w',encoding='utf-8') as f:\n",
    "            json.dump(self.run_data, f, ensure_ascii=False, indent=4)\n",
    "\n",
    "#Network\n",
    "class Network(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=6, kernel_size=5)\n",
    "        self.conv2 = nn.Conv2d(in_channels=6, out_channels=12, kernel_size=5)\n",
    "\n",
    "        self.fc1 = nn.Linear(in_features=12*4*4, out_features=120)\n",
    "        self.fc2 = nn.Linear(in_features=120, out_features=60)\n",
    "        self.out = nn.Linear(in_features=60, out_features=10)\n",
    "\n",
    "    def forward(self, t):\n",
    "        # (1) input layer\n",
    "        t = t\n",
    "\n",
    "        # (2) hidden conv layer\n",
    "        t = self.conv1(t)\n",
    "        t = F.relu(t)\n",
    "        t = F.max_pool2d(t, kernel_size=2, stride=2)\n",
    "\n",
    "        # (3) hidden conv layer\n",
    "        t = self.conv2(t)\n",
    "        t = F.relu(t)\n",
    "        t = F.max_pool2d(t, kernel_size=2, stride=2)\n",
    "\n",
    "        # (4) hidden linear layer\n",
    "        t = t.reshape(-1, 12*4*4)\n",
    "        t = self.fc1(t)\n",
    "        t = F.relu(t)\n",
    "\n",
    "        # (5) hidden linear layer\n",
    "        t = self.fc2(t)\n",
    "        t = F.relu(t)\n",
    "\n",
    "        # (6) output layer\n",
    "        t = self.out(t)\n",
    "        #t = F.softmax(t,dim=1)\n",
    "\n",
    "        return t\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Starting parameter values\n",
    "train_set = torchvision.datasets.FashionMNIST(\n",
    "    root='./data/FashionMNIST', train=True, download=True, transform=transforms.Compose([transforms.ToTensor()\n",
    "                                                                                         ])\n",
    ")\n",
    "\n",
    "params = OrderedDict(\n",
    "    lr = [.01]\n",
    "    ,batch_size = [20000]\n",
    "    ,num_workers = [1]\n",
    "    , device = ['cuda']\n",
    ")\n",
    "\n",
    "ResDir = 'runs_results'\n",
    "file_num = '1208_1725'\n",
    "m=RunManager()\n",
    "\n",
    "\n",
    "#the actual network looping\n",
    "for run in RunBuilder.get_runs(params):\n",
    "    \n",
    "    device = torch.device(run.device)\n",
    "    network = Network().to(device)\n",
    "    loader = DataLoader(train_set,batch_size=run.batch_size,num_workers = run.num_workers)\n",
    "    optimiser = optim.Adam(network.parameters(),lr=run.lr)\n",
    "    \n",
    "    m.begin_run(run,network,loader)\n",
    "    for epoch in range(1):\n",
    "        m.begin_epoch()\n",
    "        for batch in loader:\n",
    "            \n",
    "            images = batch[0].to(device)\n",
    "            labels = batch[1].to(device)\n",
    "            preds = network(images) #pass batch\n",
    "            loss = F.cross_entropy(preds,labels)\n",
    "            optimiser.zero_grad()\n",
    "            loss.backward()\n",
    "            optimiser.step()\n",
    "            \n",
    "            m.track_loss(loss)\n",
    "            m.track_num_correct(preds,labels)\n",
    "        m.end_epoch()\n",
    "    m.end_run()\n",
    "m.save(NameFile.nameit(params),ResDir,file_num) #mooie naam voor de results file met alle parameter values erin\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = DataLoader(train_set,batch_size=len(train_set),num_workers = 1)\n",
    "data = next(iter(loader))\n",
    "mean=data[0].mean()\n",
    "std=data[0].std()\n",
    "\n",
    "plt.hist(data[0].flatten())\n",
    "plt.axvline(data[0].mean())\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set_normal = torchvision.datasets.FashionMNIST(\n",
    "    root='./data/FashionMNIST'\n",
    "    , train=True\n",
    "    , download=True\n",
    "    , transform=transforms.Compose([\n",
    "          transforms.ToTensor()\n",
    "        , transforms.Normalize(mean,std)\n",
    "    ])\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = DataLoader(train_set,batch_size=len(train_set),num_workers = 1)\n",
    "data = next(iter(loader))\n",
    "data[0].mean(),data[0].std()\n",
    "\n",
    "plt.hist(data[0].flatten())\n",
    "plt.axvline(data[0].mean())\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainsets = {\n",
    "    'not_normal': train_set\n",
    "    ,'normal':train_set_normal\n",
    "}\n",
    "\n",
    "params = OrderedDict(\n",
    "    lr = [.01]\n",
    "    ,batch_size = [1000]\n",
    "    ,num_workers = [1]\n",
    "    , device = ['cuda']\n",
    "    , trainset = ['not_normal','normal']\n",
    ")\n",
    "file_num = '1208_1725_2'\n",
    "m=RunManager()\n",
    "\n",
    "\n",
    "#the actual network looping\n",
    "for run in RunBuilder.get_runs(params):\n",
    "    \n",
    "    device = torch.device(run.device)\n",
    "    network = Network().to(device)\n",
    "    loader = DataLoader(trainsets[run.trainset],batch_size=run.batch_size,num_workers = run.num_workers)\n",
    "    optimiser = optim.Adam(network.parameters(),lr=run.lr)\n",
    "    \n",
    "    m.begin_run(run,network,loader)\n",
    "    for epoch in range(2):\n",
    "        m.begin_epoch()\n",
    "        for batch in loader:\n",
    "            \n",
    "            images = batch[0].to(device)\n",
    "            print(batch[0])\n",
    "            print(batch[0].shape)\n",
    "            print(batch[0].shape[0])\n",
    "            labels = batch[1].to(device)\n",
    "            preds = network(images) #pass batch\n",
    "            loss = F.cross_entropy(preds,labels)\n",
    "            optimiser.zero_grad()\n",
    "            loss.backward()\n",
    "            optimiser.step()\n",
    "            \n",
    "            m.track_loss(loss) #hij geeft sinds die cuda unit batch mee, om batch[0].shape[0] mee te geven als batchsize. zou niet weten waarom self.loader.batch_size ineens niet meer zou werken\n",
    "            m.track_num_correct(preds,labels)\n",
    "        m.end_epoch()\n",
    "    m.end_run()\n",
    "m.save(NameFile.nameit(params),ResDir,file_num) #mooie naam voor de results file met alle parameter values erin\n",
    "\n",
    "pd.DataFrame.from_dict(m.run_data).sort_values('accuracy',ascending=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trying multiple networks 39"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(50)\n",
    "network1 = nn.Sequential(\n",
    "    nn.Conv2d(in_channels=1, out_channels=6, kernel_size=5)\n",
    "    ,nn.ReLU()\n",
    "    ,nn.MaxPool2d(kernel_size=2,stride=2)\n",
    "    ,nn.Conv2d(in_channels=6, out_channels=12, kernel_size=5)\n",
    "    ,nn.ReLU()\n",
    "    ,nn.MaxPool2d(kernel_size=2,stride=2)\n",
    "    ,nn.Flatten(start_dim=1)\n",
    "    ,nn.Linear(in_features=12*4*4,out_features=120)\n",
    "    ,nn.ReLU()\n",
    "    ,nn.Linear(in_features=120,out_features=60)\n",
    "    ,nn.ReLU()\n",
    "    ,nn.Linear(in_features=60,out_features=10)   \n",
    ")\n",
    "\n",
    "torch.manual_seed(50)\n",
    "network2 = nn.Sequential(\n",
    "    nn.Conv2d(in_channels=1, out_channels=6, kernel_size=5)\n",
    "    ,nn.ReLU()\n",
    "    ,nn.MaxPool2d(kernel_size=2,stride=2)\n",
    "    ,nn.BatchNorm2d(6)\n",
    "    ,nn.Conv2d(in_channels=6, out_channels=12, kernel_size=5)\n",
    "    ,nn.ReLU()\n",
    "    ,nn.MaxPool2d(kernel_size=2,stride=2)\n",
    "    ,nn.Flatten(start_dim=1)\n",
    "    ,nn.Linear(in_features=12*4*4,out_features=120)\n",
    "    ,nn.ReLU()\n",
    "    ,nn.BatchNorm1d(120)\n",
    "    ,nn.Linear(in_features=120,out_features=60)\n",
    "    ,nn.ReLU()\n",
    "    ,nn.Linear(in_features=60,out_features=10)   \n",
    ")\n",
    "\n",
    "networks = {\n",
    "    'network1': network1\n",
    "    ,'network2':network2\n",
    "}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = OrderedDict(\n",
    "lr = [.01]\n",
    ",batch_size = [1000]\n",
    ",num_workers = [1]\n",
    ",device = ['cuda']\n",
    ",trainset = ['normal']\n",
    ",network=list(networks.keys())\n",
    ")\n",
    "\n",
    "ResDir = 'runs_results'\n",
    "file_num = '1208_1725_3'\n",
    "m=RunManager()\n",
    "\n",
    "#the actual network looping\n",
    "for run in RunBuilder.get_runs(params):\n",
    "    \n",
    "    device = torch.device(run.device)\n",
    "    network = Network().to(device)\n",
    "    loader = DataLoader(trainsets[run.trainset],batch_size=run.batch_size,num_workers = run.num_workers)\n",
    "    optimiser = optim.Adam(network.parameters(),lr=run.lr)\n",
    "    \n",
    "    m.begin_run(run,network,loader)\n",
    "    for epoch in range(2):\n",
    "        m.begin_epoch()\n",
    "        for batch in loader:\n",
    "            \n",
    "            images = batch[0].to(device)\n",
    "            print(batch[0])\n",
    "            print(batch[0].shape)\n",
    "            print(batch[0].shape[0])\n",
    "            labels = batch[1].to(device)\n",
    "            preds = network(images) #pass batch\n",
    "            loss = F.cross_entropy(preds,labels)\n",
    "            optimiser.zero_grad()\n",
    "            loss.backward()\n",
    "            optimiser.step()\n",
    "            \n",
    "            m.track_loss(loss) #hij geeft sinds die cuda unit batch mee, om batch[0].shape[0] mee te geven als batchsize. zou niet weten waarom self.loader.batch_size ineens niet meer zou werken\n",
    "            m.track_num_correct(preds,labels)\n",
    "        m.end_epoch()\n",
    "    m.end_run()\n",
    "m.save(NameFile.nameit(params),ResDir,file_num) #mooie naam voor de results file met alle parameter values erinplt.hist(data[0].flatten())\n",
    "plt.axvline(data[0].mean())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
