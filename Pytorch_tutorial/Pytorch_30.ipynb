{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.5.1\n",
      "0.6.1\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "torch.set_printoptions(linewidth=120)\n",
    "torch.set_grad_enabled(True)\n",
    "\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "print(torch.__version__)\n",
    "print(torchvision.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_num_correct(preds, labels):\n",
    "    return preds.argmax(dim=1).eq(labels).sum().item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Network(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=6, kernel_size=5)\n",
    "        self.conv2 = nn.Conv2d(in_channels=6, out_channels=12, kernel_size=5)\n",
    "\n",
    "        self.fc1 = nn.Linear(in_features=12*4*4, out_features=120)\n",
    "        self.fc2 = nn.Linear(in_features=120, out_features=60)\n",
    "        self.out = nn.Linear(in_features=60, out_features=10)\n",
    "\n",
    "    def forward(self, t):\n",
    "        # (1) input layer\n",
    "        t = t\n",
    "\n",
    "        # (2) hidden conv layer\n",
    "        t = self.conv1(t)\n",
    "        t = F.relu(t)\n",
    "        t = F.max_pool2d(t, kernel_size=2, stride=2)\n",
    "\n",
    "        # (3) hidden conv layer\n",
    "        t = self.conv2(t)\n",
    "        t = F.relu(t)\n",
    "        t = F.max_pool2d(t, kernel_size=2, stride=2)\n",
    "\n",
    "        # (4) hidden linear layer\n",
    "        t = t.reshape(-1, 12*4*4)\n",
    "        t = self.fc1(t)\n",
    "        t = F.relu(t)\n",
    "\n",
    "        # (5) hidden linear layer\n",
    "        t = self.fc2(t)\n",
    "        t = F.relu(t)\n",
    "\n",
    "        # (6) output layer\n",
    "        t = self.out(t)\n",
    "        #t = F.softmax(t,dim=1)\n",
    "\n",
    "        return t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = torchvision.datasets.FashionMNIST(\n",
    "    root='./data/FashionMNIST', train=True, download=True, transform=transforms.Compose([transforms.ToTensor()\n",
    "                                                                                         ])\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(train_set, batch_size=100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "tb = SummaryWriter()\n",
    "\n",
    "network = Network()\n",
    "images,labels=next(iter(train_loader))\n",
    "grid = torchvision.utils.make_grid(images)\n",
    "\n",
    "tb.add_image('images',grid)\n",
    "tb.add_graph(network,images)\n",
    "tb.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0 total_correct: 46621 loss: 351.3138353228569\n"
     ]
    }
   ],
   "source": [
    "network = Network()\n",
    "train_loader = torch.utils.data.DataLoader(train_set, batch_size=100,shuffle=True)\n",
    "optimiser = optim.Adam(network.parameters(),lr=0.01)\n",
    "\n",
    "for epoch in range(1):\n",
    "    \n",
    "    total_loss=0\n",
    "    total_correct=0\n",
    "    \n",
    "    for batch in train_loader:\n",
    "        images, labels = batch\n",
    "        \n",
    "        preds = network(images)\n",
    "        loss = F.cross_entropy(preds,labels)\n",
    "        \n",
    "        optimiser.zero_grad()\n",
    "        loss.backward()\n",
    "        optimiser.step()\n",
    "        \n",
    "        total_loss+=loss.item()\n",
    "        total_correct+=get_num_correct(preds,labels)\n",
    "        \n",
    "    print(\"epoch\",epoch,\"total_correct:\",total_correct,\"loss:\",total_loss )\n",
    "\n",
    "images,labels=next(iter(train_loader))\n",
    "grid = torchvision.utils.make_grid(images)\n",
    "\n",
    "tb.add_image('images',grid)\n",
    "tb.add_graph(network,images)\n",
    "tb.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0 total_correct: 46432 loss: 352.4348495006561\n",
      "epoch 1 total_correct: 51148 loss: 238.2791469693184\n",
      "epoch 2 total_correct: 51956 loss: 216.7793028652668\n",
      "epoch 3 total_correct: 52355 loss: 207.47387935221195\n",
      "epoch 4 total_correct: 52645 loss: 199.68736720085144\n",
      "epoch 5 total_correct: 52902 loss: 194.29091149568558\n",
      "epoch 6 total_correct: 52948 loss: 191.0817735120654\n",
      "epoch 7 total_correct: 53168 loss: 185.4342116266489\n",
      "epoch 8 total_correct: 53168 loss: 186.0882028415799\n",
      "epoch 9 total_correct: 53348 loss: 182.46192450076342\n"
     ]
    }
   ],
   "source": [
    "network = Network()\n",
    "train_loader = torch.utils.data.DataLoader(train_set, batch_size=100,shuffle=True)\n",
    "optimiser = optim.Adam(network.parameters(),lr=0.01)\n",
    "\n",
    "images,labels = next(iter(train_loader))\n",
    "grid = torchvision.utils.make_grid(images)\n",
    "\n",
    "tb = SummaryWriter()\n",
    "tb.add_image('images',grid)\n",
    "tb.add_graph(network,images)\n",
    "\n",
    "for epoch in range(10):\n",
    "    \n",
    "    total_loss=0\n",
    "    total_correct=0\n",
    "    \n",
    "    for batch in train_loader:\n",
    "        images, labels = batch\n",
    "        \n",
    "        preds = network(images)\n",
    "        loss = F.cross_entropy(preds,labels)\n",
    "        \n",
    "        optimiser.zero_grad()\n",
    "        loss.backward()\n",
    "        optimiser.step()\n",
    "        \n",
    "        total_loss+=loss.item()\n",
    "        total_correct+=get_num_correct(preds,labels)\n",
    "        \n",
    "\n",
    "    tb.add_scalar('Loss',total_loss,epoch)\n",
    "    tb.add_scalar('Number Correct',total_correct,epoch)\n",
    "    tb.add_scalar('Accuracy',total_correct/len(train_set),epoch)\n",
    "\n",
    "    tb.add_histogram('conv1.bias',network.conv1.bias,epoch)\n",
    "    tb.add_histogram('conv1.weight',network.conv1.weight,epoch)\n",
    "    tb.add_histogram('conv1.weight.grad',network.conv1.weight.grad,epoch)\n",
    "\n",
    "    print(\"epoch\",epoch,\"total_correct:\",total_correct,\"loss:\",total_loss )\n",
    "\n",
    "tb.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
