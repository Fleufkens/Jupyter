{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from IPython.display import display, clear_output\n",
    "import pandas as pd\n",
    "import time\n",
    "import json\n",
    "\n",
    "from itertools import product\n",
    "from collections import namedtuple\n",
    "from collections import OrderedDict\n",
    "\n",
    "import os \n",
    "\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#NameFile\n",
    "class NameFile():\n",
    "    @staticmethod#static? iets met dat je m kan callen using the class itself. don't need an instance of the class, to call the method. i guess dat je m dus niet eerst hoeft te initieren alszijnde type x? \n",
    "    def nameit(params): #ga er dus vanuit dat je alleen keys and values hebt, dus alleen 0 en 1 voor die ene index. wellicht gaat dit dus ooit mis, makkelijk te herstellen\n",
    "\n",
    "        items_hier = list(params.items()) #keys+values\n",
    "        num_k=0 #amount of keys present\n",
    "        comment = '' #the string for the filename\n",
    "        \n",
    "        #make the comment by looping over keys and values\n",
    "        for k in params.keys():\n",
    "            comment += f'{items_hier[num_k][0]}=' #add the key\n",
    "            for v in items_hier[num_k][1]:\n",
    "                comment +=(f'{v}_') #add the values\n",
    "            num_k+=1 #for indexing next loop to get next keys/values in list\n",
    "        comment+='results'\n",
    "        return comment\n",
    "\n",
    "#RunBuilder\n",
    "class RunBuilder():\n",
    "    @staticmethod#static? iets met dat je m kan callen using the class itself. don't need an instance of the class, to call the method. i guess dat je m dus niet eerst hoeft te initieren alszijnde type x? \n",
    "    def get_runs(params):\n",
    "        \n",
    "        Run = namedtuple('Run',params.keys())#die ordereddicttionary heeft keys and values. dit heb je wel eens eerder gezien I guess.\n",
    "                                             #blijkbaar maakt ie een mooie string als je die keys zo oproept. test dat even.\n",
    "        \n",
    "        runs = []\n",
    "        for v in product(*params.values()): #dit doet dus iets dat ie per value combo nieuwe iteratie doet\n",
    "            runs.append(Run(*v))\n",
    "            \n",
    "        return runs\n",
    "\n",
    "#RunManager\n",
    "class RunManager():\n",
    "    def __init__(self):\n",
    "        \n",
    "        self.epoch_count = 0\n",
    "        self.epoch_loss = 0\n",
    "        self.epoch_num_correct = 0\n",
    "        self.epoch_start_time = None\n",
    "        \n",
    "        self.run_params = None\n",
    "        self.run_count = 0\n",
    "        self.run_data = []\n",
    "        self.run_start_time = None\n",
    "        \n",
    "        self.network = None\n",
    "        self.loader = None\n",
    "        self.tb = None\n",
    "\n",
    "    def begin_run(self,run,network,loader): #die self is dus gewoon de variabel naam links van de streep\n",
    "        #start time for a run, parameters run added, run_count+1 (stays same for all epochs)\n",
    "        #network copied, loader copied, name given in tb. \n",
    "        self.run_start_time = time.time()\n",
    "        \n",
    "        self.run_params = run\n",
    "        self.run_count += 1\n",
    "        self.network = network\n",
    "        self.loader = loader\n",
    "        self.tb = SummaryWriter(comment=f'-{run}')\n",
    "        \n",
    "        images,labels = next(iter(self.loader)) #misschien wel gewoon plaatjes inladen voor foto'tje in tensorboard\n",
    "        grid = torchvision.utils.make_grid(images)\n",
    "        \n",
    "        self.tb.add_image('images',grid)\n",
    "        self.tb.add_graph(\n",
    "            self.network\n",
    "            ,images.to(getattr(run,'device','cpu')))\n",
    "        \n",
    "    def end_run(self):\n",
    "        self.tb.close()\n",
    "        self.epoch_count = 0\n",
    "\n",
    "    def begin_epoch(self):\n",
    "        self.epoch_start_time = time.time()\n",
    "        \n",
    "        self.epoch_count += 1\n",
    "        self.epoch_loss = 0\n",
    "        self.epoch_num_correct = 0\n",
    "        \n",
    "    def end_epoch(self):\n",
    "        \n",
    "        epoch_duration = time.time()-self.epoch_start_time\n",
    "        run_duration = time.time()-self.run_start_time\n",
    "        \n",
    "        loss = self.epoch_loss/len(self.loader.dataset)\n",
    "        accuracy = self.epoch_num_correct/len(self.loader.dataset)\n",
    "        \n",
    "        self.tb.add_scalar('Loss',loss,self.epoch_count)\n",
    "        self.tb.add_scalar('Accuracy',accuracy,self.epoch_count)\n",
    "        \n",
    "        for name, param in self.network.named_parameters():\n",
    "            self.tb.add_histogram(name,param,self.epoch_count)\n",
    "            self.tb.add_histogram(f'{name}.grad',param.grad,self.epoch_count)\n",
    "            \n",
    "        results = OrderedDict()\n",
    "        results[\"run\"]=self.run_count\n",
    "        results[\"epoch\"]=self.epoch_count\n",
    "        results[\"loss\"]=loss\n",
    "        results[\"accuracy\"]=accuracy\n",
    "        results[\"epoch duration\"]=epoch_duration\n",
    "        results[\"run duration\"]=run_duration\n",
    "                            \n",
    "        for k,v in self.run_params._asdict().items():  #deze komen uit run, je batch_size & lr\n",
    "            results[k] = v #geloof dat je hier dus voor elke run met andere batch size etc. maar 1 lr en batchsize toevoegt, vandaar dat dit niet in de loop zit\n",
    "        self.run_data.append(results) #1 batch_size en lr bij de results bij, en vervolgens voeg je al je results toe aan wat je metadata i guess\n",
    "        df = pd.DataFrame.from_dict(self.run_data,orient='columns') #dit zorgt dat het in een leuk tabelletje staat\n",
    "                                \n",
    "        clear_output(wait=True)\n",
    "        display(df)\n",
    "                                \n",
    "    def track_loss(self,loss):\n",
    "            self.epoch_loss += loss.item()* self.loader.batch_size\n",
    "                                    \n",
    "    def track_num_correct(self,preds,labels):\n",
    "            self.epoch_num_correct += self._get_num_correct(preds,labels)\n",
    "        \n",
    "    @torch.no_grad()\n",
    "    def _get_num_correct(self,preds,labels):\n",
    "        return preds.argmax(dim=1).eq(labels).sum().item()\n",
    "    \n",
    "    def save(self,fileName,ResDir,file_num):\n",
    "        \n",
    "        os.mkdir(f'{ResDir}\\{file_num}')\n",
    "        \n",
    "        pd.DataFrame.from_dict(\n",
    "        self.run_data\n",
    "        ,orient = 'columns'\n",
    "        ).to_csv(f'{ResDir}\\{file_num}\\{fileName}.csv')\n",
    "        \n",
    "        with open(f'{ResDir}\\{file_num}\\{fileName}.json','w',encoding='utf-8') as f:\n",
    "            json.dump(self.run_data, f, ensure_ascii=False, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(50)\n",
    "network1 = nn.Sequential(\n",
    "    nn.Conv2d(in_channels=1, out_channels=6, kernel_size=5)\n",
    "    ,nn.ReLU()\n",
    "    ,nn.MaxPool2d(kernel_size=2,stride=2)\n",
    "    ,nn.Conv2d(in_channels=6, out_channels=12, kernel_size=5)\n",
    "    ,nn.ReLU()\n",
    "    ,nn.MaxPool2d(kernel_size=2,stride=2)\n",
    "    ,nn.Flatten(start_dim=1)\n",
    "    ,nn.Linear(in_features=12*4*4,out_features=120)\n",
    "    ,nn.ReLU()\n",
    "    ,nn.Linear(in_features=120,out_features=60)\n",
    "    ,nn.ReLU()\n",
    "    ,nn.Linear(in_features=60,out_features=10)   \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(50)\n",
    "network2 = nn.Sequential(\n",
    "    nn.Conv2d(in_channels=1, out_channels=6, kernel_size=5)\n",
    "    ,nn.ReLU()\n",
    "    ,nn.MaxPool2d(kernel_size=2,stride=2)\n",
    "    ,nn.BatchNorm2d(6)\n",
    "    ,nn.Conv2d(in_channels=6, out_channels=12, kernel_size=5)\n",
    "    ,nn.ReLU()\n",
    "    ,nn.MaxPool2d(kernel_size=2,stride=2)\n",
    "    ,nn.Flatten(start_dim=1)\n",
    "    ,nn.Linear(in_features=12*4*4,out_features=120)\n",
    "    ,nn.ReLU()\n",
    "    ,nn.BatchNorm1d(120)\n",
    "    ,nn.Linear(in_features=120,out_features=60)\n",
    "    ,nn.ReLU()\n",
    "    ,nn.Linear(in_features=60,out_features=10)   \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = torchvision.datasets.FashionMNIST(\n",
    "root='./data'\n",
    "    ,download=True\n",
    "    ,train=True\n",
    "    ,transform=transforms.Compose([\n",
    "        transforms.ToTensor()\n",
    "    ])\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0.2861), tensor(0.3530))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loader = DataLoader(train_set,batch_size=len(train_set),num_workers=1)\n",
    "data=next(iter(loader))\n",
    "mean = data[0].mean()\n",
    "std = data[0].std()\n",
    "mean,std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set_normal = torchvision.datasets.FashionMNIST(\n",
    "root='./data'\n",
    "    ,download=True\n",
    "    ,train=True\n",
    "    ,transform=transforms.Compose([\n",
    "        transforms.ToTensor()\n",
    "        ,transforms.Normalize(mean,std)\n",
    "    ])\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainsets = {\n",
    "    'not_normal': train_set\n",
    "    ,'normal':train_set_normal\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "networks = {\n",
    "    'no_batch_norm': network1\n",
    "    ,'batch_norm':network2\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>run</th>\n",
       "      <th>epoch</th>\n",
       "      <th>loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>epoch duration</th>\n",
       "      <th>run duration</th>\n",
       "      <th>lr</th>\n",
       "      <th>batch_size</th>\n",
       "      <th>num_workers</th>\n",
       "      <th>device</th>\n",
       "      <th>trainset</th>\n",
       "      <th>network</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.010034</td>\n",
       "      <td>0.606967</td>\n",
       "      <td>7.325416</td>\n",
       "      <td>13.160287</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1000</td>\n",
       "      <td>1</td>\n",
       "      <td>cuda</td>\n",
       "      <td>not_normal</td>\n",
       "      <td>no_batch_norm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.545249</td>\n",
       "      <td>0.788833</td>\n",
       "      <td>7.605963</td>\n",
       "      <td>20.910635</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1000</td>\n",
       "      <td>1</td>\n",
       "      <td>cuda</td>\n",
       "      <td>not_normal</td>\n",
       "      <td>no_batch_norm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0.465293</td>\n",
       "      <td>0.828217</td>\n",
       "      <td>6.844383</td>\n",
       "      <td>27.916469</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1000</td>\n",
       "      <td>1</td>\n",
       "      <td>cuda</td>\n",
       "      <td>not_normal</td>\n",
       "      <td>no_batch_norm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0.411397</td>\n",
       "      <td>0.849217</td>\n",
       "      <td>7.194037</td>\n",
       "      <td>35.216199</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1000</td>\n",
       "      <td>1</td>\n",
       "      <td>cuda</td>\n",
       "      <td>not_normal</td>\n",
       "      <td>no_batch_norm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0.374156</td>\n",
       "      <td>0.862267</td>\n",
       "      <td>7.476776</td>\n",
       "      <td>42.786971</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1000</td>\n",
       "      <td>1</td>\n",
       "      <td>cuda</td>\n",
       "      <td>not_normal</td>\n",
       "      <td>no_batch_norm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>4</td>\n",
       "      <td>16</td>\n",
       "      <td>0.125689</td>\n",
       "      <td>0.952133</td>\n",
       "      <td>9.969344</td>\n",
       "      <td>165.065828</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1000</td>\n",
       "      <td>1</td>\n",
       "      <td>cuda</td>\n",
       "      <td>normal</td>\n",
       "      <td>batch_norm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>4</td>\n",
       "      <td>17</td>\n",
       "      <td>0.120762</td>\n",
       "      <td>0.952700</td>\n",
       "      <td>10.230132</td>\n",
       "      <td>175.442173</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1000</td>\n",
       "      <td>1</td>\n",
       "      <td>cuda</td>\n",
       "      <td>normal</td>\n",
       "      <td>batch_norm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>4</td>\n",
       "      <td>18</td>\n",
       "      <td>0.115337</td>\n",
       "      <td>0.955033</td>\n",
       "      <td>9.984033</td>\n",
       "      <td>185.624281</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1000</td>\n",
       "      <td>1</td>\n",
       "      <td>cuda</td>\n",
       "      <td>normal</td>\n",
       "      <td>batch_norm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>4</td>\n",
       "      <td>19</td>\n",
       "      <td>0.115360</td>\n",
       "      <td>0.955300</td>\n",
       "      <td>9.918997</td>\n",
       "      <td>195.681020</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1000</td>\n",
       "      <td>1</td>\n",
       "      <td>cuda</td>\n",
       "      <td>normal</td>\n",
       "      <td>batch_norm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>4</td>\n",
       "      <td>20</td>\n",
       "      <td>0.110408</td>\n",
       "      <td>0.957317</td>\n",
       "      <td>10.035356</td>\n",
       "      <td>205.923431</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1000</td>\n",
       "      <td>1</td>\n",
       "      <td>cuda</td>\n",
       "      <td>normal</td>\n",
       "      <td>batch_norm</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>80 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    run  epoch      loss  accuracy  epoch duration  run duration    lr  \\\n",
       "0     1      1  1.010034  0.606967        7.325416     13.160287  0.01   \n",
       "1     1      2  0.545249  0.788833        7.605963     20.910635  0.01   \n",
       "2     1      3  0.465293  0.828217        6.844383     27.916469  0.01   \n",
       "3     1      4  0.411397  0.849217        7.194037     35.216199  0.01   \n",
       "4     1      5  0.374156  0.862267        7.476776     42.786971  0.01   \n",
       "..  ...    ...       ...       ...             ...           ...   ...   \n",
       "75    4     16  0.125689  0.952133        9.969344    165.065828  0.01   \n",
       "76    4     17  0.120762  0.952700       10.230132    175.442173  0.01   \n",
       "77    4     18  0.115337  0.955033        9.984033    185.624281  0.01   \n",
       "78    4     19  0.115360  0.955300        9.918997    195.681020  0.01   \n",
       "79    4     20  0.110408  0.957317       10.035356    205.923431  0.01   \n",
       "\n",
       "    batch_size  num_workers device    trainset        network  \n",
       "0         1000            1   cuda  not_normal  no_batch_norm  \n",
       "1         1000            1   cuda  not_normal  no_batch_norm  \n",
       "2         1000            1   cuda  not_normal  no_batch_norm  \n",
       "3         1000            1   cuda  not_normal  no_batch_norm  \n",
       "4         1000            1   cuda  not_normal  no_batch_norm  \n",
       "..         ...          ...    ...         ...            ...  \n",
       "75        1000            1   cuda      normal     batch_norm  \n",
       "76        1000            1   cuda      normal     batch_norm  \n",
       "77        1000            1   cuda      normal     batch_norm  \n",
       "78        1000            1   cuda      normal     batch_norm  \n",
       "79        1000            1   cuda      normal     batch_norm  \n",
       "\n",
       "[80 rows x 12 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "params = OrderedDict(\n",
    "    lr = [.01]\n",
    "    ,batch_size = [1000]\n",
    "    ,num_workers = [1]\n",
    "    ,device = ['cuda']\n",
    "    ,trainset = list(trainsets.keys())\n",
    "    ,network=list(networks.keys())\n",
    ")\n",
    "\n",
    "ResDir = 'runs_results'\n",
    "file_num = '1308_1439'\n",
    "m=RunManager()\n",
    "\n",
    "for run in RunBuilder.get_runs(params):\n",
    "    \n",
    "    device=torch.device(run.device)\n",
    "    network = networks[run.network].to(device)\n",
    "    loader = DataLoader(trainsets[run.trainset],batch_size=run.batch_size,num_workers=run.num_workers)\n",
    "    optimiser = optim.Adam(network.parameters(),lr=run.lr)\n",
    "    \n",
    "    m.begin_run(run,network,loader)\n",
    "    for epoch in range(20):\n",
    "        m.begin_epoch()\n",
    "        for batch in loader:\n",
    "            \n",
    "            images = batch[0].to(device)\n",
    "            labels = batch[1].to(device)\n",
    "            preds = network(images)\n",
    "            loss = F.cross_entropy(preds,labels)\n",
    "            optimiser.zero_grad()\n",
    "            loss.backward()\n",
    "            optimiser.step()\n",
    "            \n",
    "            m.track_loss(loss)\n",
    "            m.track_num_correct(preds,labels)\n",
    "        m.end_epoch()\n",
    "    m.end_run()\n",
    "m.save(NameFile.nameit(params),ResDir,file_num) #mooie naam voor de results file met alle parameter values erin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>run</th>\n",
       "      <th>epoch</th>\n",
       "      <th>loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>epoch duration</th>\n",
       "      <th>run duration</th>\n",
       "      <th>lr</th>\n",
       "      <th>batch_size</th>\n",
       "      <th>num_workers</th>\n",
       "      <th>device</th>\n",
       "      <th>trainset</th>\n",
       "      <th>network</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>4</td>\n",
       "      <td>20</td>\n",
       "      <td>0.110408</td>\n",
       "      <td>0.957317</td>\n",
       "      <td>10.035356</td>\n",
       "      <td>205.923431</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1000</td>\n",
       "      <td>1</td>\n",
       "      <td>cuda</td>\n",
       "      <td>normal</td>\n",
       "      <td>batch_norm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>4</td>\n",
       "      <td>19</td>\n",
       "      <td>0.115360</td>\n",
       "      <td>0.955300</td>\n",
       "      <td>9.918997</td>\n",
       "      <td>195.681020</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1000</td>\n",
       "      <td>1</td>\n",
       "      <td>cuda</td>\n",
       "      <td>normal</td>\n",
       "      <td>batch_norm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>4</td>\n",
       "      <td>18</td>\n",
       "      <td>0.115337</td>\n",
       "      <td>0.955033</td>\n",
       "      <td>9.984033</td>\n",
       "      <td>185.624281</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1000</td>\n",
       "      <td>1</td>\n",
       "      <td>cuda</td>\n",
       "      <td>normal</td>\n",
       "      <td>batch_norm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>4</td>\n",
       "      <td>17</td>\n",
       "      <td>0.120762</td>\n",
       "      <td>0.952700</td>\n",
       "      <td>10.230132</td>\n",
       "      <td>175.442173</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1000</td>\n",
       "      <td>1</td>\n",
       "      <td>cuda</td>\n",
       "      <td>normal</td>\n",
       "      <td>batch_norm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>4</td>\n",
       "      <td>16</td>\n",
       "      <td>0.125689</td>\n",
       "      <td>0.952133</td>\n",
       "      <td>9.969344</td>\n",
       "      <td>165.065828</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1000</td>\n",
       "      <td>1</td>\n",
       "      <td>cuda</td>\n",
       "      <td>normal</td>\n",
       "      <td>batch_norm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>4</td>\n",
       "      <td>15</td>\n",
       "      <td>0.137869</td>\n",
       "      <td>0.948017</td>\n",
       "      <td>10.467396</td>\n",
       "      <td>154.903531</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1000</td>\n",
       "      <td>1</td>\n",
       "      <td>cuda</td>\n",
       "      <td>normal</td>\n",
       "      <td>batch_norm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>4</td>\n",
       "      <td>14</td>\n",
       "      <td>0.139621</td>\n",
       "      <td>0.946200</td>\n",
       "      <td>9.497421</td>\n",
       "      <td>144.227819</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1000</td>\n",
       "      <td>1</td>\n",
       "      <td>cuda</td>\n",
       "      <td>normal</td>\n",
       "      <td>batch_norm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>4</td>\n",
       "      <td>13</td>\n",
       "      <td>0.145431</td>\n",
       "      <td>0.944733</td>\n",
       "      <td>10.374502</td>\n",
       "      <td>134.604298</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1000</td>\n",
       "      <td>1</td>\n",
       "      <td>cuda</td>\n",
       "      <td>normal</td>\n",
       "      <td>batch_norm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>4</td>\n",
       "      <td>12</td>\n",
       "      <td>0.146747</td>\n",
       "      <td>0.943683</td>\n",
       "      <td>10.059436</td>\n",
       "      <td>124.028419</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1000</td>\n",
       "      <td>1</td>\n",
       "      <td>cuda</td>\n",
       "      <td>normal</td>\n",
       "      <td>batch_norm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>4</td>\n",
       "      <td>11</td>\n",
       "      <td>0.155680</td>\n",
       "      <td>0.940317</td>\n",
       "      <td>9.997989</td>\n",
       "      <td>113.749509</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1000</td>\n",
       "      <td>1</td>\n",
       "      <td>cuda</td>\n",
       "      <td>normal</td>\n",
       "      <td>batch_norm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>0.156015</td>\n",
       "      <td>0.939800</td>\n",
       "      <td>9.583233</td>\n",
       "      <td>103.621759</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1000</td>\n",
       "      <td>1</td>\n",
       "      <td>cuda</td>\n",
       "      <td>normal</td>\n",
       "      <td>batch_norm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>0.156590</td>\n",
       "      <td>0.939717</td>\n",
       "      <td>9.703273</td>\n",
       "      <td>83.628218</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1000</td>\n",
       "      <td>1</td>\n",
       "      <td>cuda</td>\n",
       "      <td>normal</td>\n",
       "      <td>batch_norm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>0.160415</td>\n",
       "      <td>0.939133</td>\n",
       "      <td>10.417717</td>\n",
       "      <td>54.451969</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1000</td>\n",
       "      <td>1</td>\n",
       "      <td>cuda</td>\n",
       "      <td>normal</td>\n",
       "      <td>batch_norm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>0.158894</td>\n",
       "      <td>0.939100</td>\n",
       "      <td>9.588355</td>\n",
       "      <td>73.804569</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1000</td>\n",
       "      <td>1</td>\n",
       "      <td>cuda</td>\n",
       "      <td>normal</td>\n",
       "      <td>batch_norm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>0.157441</td>\n",
       "      <td>0.938900</td>\n",
       "      <td>9.986464</td>\n",
       "      <td>93.843158</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1000</td>\n",
       "      <td>1</td>\n",
       "      <td>cuda</td>\n",
       "      <td>normal</td>\n",
       "      <td>batch_norm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0.163364</td>\n",
       "      <td>0.938767</td>\n",
       "      <td>10.337799</td>\n",
       "      <td>43.889219</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1000</td>\n",
       "      <td>1</td>\n",
       "      <td>cuda</td>\n",
       "      <td>normal</td>\n",
       "      <td>batch_norm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>0.161548</td>\n",
       "      <td>0.938150</td>\n",
       "      <td>9.394383</td>\n",
       "      <td>64.040888</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1000</td>\n",
       "      <td>1</td>\n",
       "      <td>cuda</td>\n",
       "      <td>normal</td>\n",
       "      <td>batch_norm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>2</td>\n",
       "      <td>20</td>\n",
       "      <td>0.167247</td>\n",
       "      <td>0.936067</td>\n",
       "      <td>7.775005</td>\n",
       "      <td>153.603966</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1000</td>\n",
       "      <td>1</td>\n",
       "      <td>cuda</td>\n",
       "      <td>not_normal</td>\n",
       "      <td>batch_norm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>2</td>\n",
       "      <td>18</td>\n",
       "      <td>0.173398</td>\n",
       "      <td>0.934700</td>\n",
       "      <td>7.604895</td>\n",
       "      <td>137.686313</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1000</td>\n",
       "      <td>1</td>\n",
       "      <td>cuda</td>\n",
       "      <td>not_normal</td>\n",
       "      <td>batch_norm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>0.174762</td>\n",
       "      <td>0.934300</td>\n",
       "      <td>10.017647</td>\n",
       "      <td>33.436595</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1000</td>\n",
       "      <td>1</td>\n",
       "      <td>cuda</td>\n",
       "      <td>normal</td>\n",
       "      <td>batch_norm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>2</td>\n",
       "      <td>19</td>\n",
       "      <td>0.172948</td>\n",
       "      <td>0.934200</td>\n",
       "      <td>7.745587</td>\n",
       "      <td>145.652274</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1000</td>\n",
       "      <td>1</td>\n",
       "      <td>cuda</td>\n",
       "      <td>not_normal</td>\n",
       "      <td>batch_norm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>2</td>\n",
       "      <td>16</td>\n",
       "      <td>0.180939</td>\n",
       "      <td>0.932733</td>\n",
       "      <td>6.491221</td>\n",
       "      <td>122.115530</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1000</td>\n",
       "      <td>1</td>\n",
       "      <td>cuda</td>\n",
       "      <td>not_normal</td>\n",
       "      <td>batch_norm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>2</td>\n",
       "      <td>17</td>\n",
       "      <td>0.177467</td>\n",
       "      <td>0.932600</td>\n",
       "      <td>7.612194</td>\n",
       "      <td>129.885850</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1000</td>\n",
       "      <td>1</td>\n",
       "      <td>cuda</td>\n",
       "      <td>not_normal</td>\n",
       "      <td>batch_norm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>2</td>\n",
       "      <td>15</td>\n",
       "      <td>0.183518</td>\n",
       "      <td>0.931867</td>\n",
       "      <td>7.085083</td>\n",
       "      <td>115.425863</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1000</td>\n",
       "      <td>1</td>\n",
       "      <td>cuda</td>\n",
       "      <td>not_normal</td>\n",
       "      <td>batch_norm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>2</td>\n",
       "      <td>14</td>\n",
       "      <td>0.193205</td>\n",
       "      <td>0.927983</td>\n",
       "      <td>7.124583</td>\n",
       "      <td>108.196270</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1000</td>\n",
       "      <td>1</td>\n",
       "      <td>cuda</td>\n",
       "      <td>not_normal</td>\n",
       "      <td>batch_norm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0.190643</td>\n",
       "      <td>0.927733</td>\n",
       "      <td>11.381498</td>\n",
       "      <td>23.290640</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1000</td>\n",
       "      <td>1</td>\n",
       "      <td>cuda</td>\n",
       "      <td>normal</td>\n",
       "      <td>batch_norm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>2</td>\n",
       "      <td>13</td>\n",
       "      <td>0.201877</td>\n",
       "      <td>0.924533</td>\n",
       "      <td>7.009605</td>\n",
       "      <td>100.900473</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1000</td>\n",
       "      <td>1</td>\n",
       "      <td>cuda</td>\n",
       "      <td>not_normal</td>\n",
       "      <td>batch_norm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>3</td>\n",
       "      <td>17</td>\n",
       "      <td>0.203397</td>\n",
       "      <td>0.924133</td>\n",
       "      <td>10.665856</td>\n",
       "      <td>187.003731</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1000</td>\n",
       "      <td>1</td>\n",
       "      <td>cuda</td>\n",
       "      <td>normal</td>\n",
       "      <td>no_batch_norm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>3</td>\n",
       "      <td>16</td>\n",
       "      <td>0.202173</td>\n",
       "      <td>0.924033</td>\n",
       "      <td>10.102604</td>\n",
       "      <td>176.150221</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1000</td>\n",
       "      <td>1</td>\n",
       "      <td>cuda</td>\n",
       "      <td>normal</td>\n",
       "      <td>no_batch_norm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>3</td>\n",
       "      <td>13</td>\n",
       "      <td>0.202723</td>\n",
       "      <td>0.923917</td>\n",
       "      <td>9.909368</td>\n",
       "      <td>145.100881</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1000</td>\n",
       "      <td>1</td>\n",
       "      <td>cuda</td>\n",
       "      <td>normal</td>\n",
       "      <td>no_batch_norm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>3</td>\n",
       "      <td>12</td>\n",
       "      <td>0.205129</td>\n",
       "      <td>0.923767</td>\n",
       "      <td>14.789005</td>\n",
       "      <td>135.029758</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1000</td>\n",
       "      <td>1</td>\n",
       "      <td>cuda</td>\n",
       "      <td>normal</td>\n",
       "      <td>no_batch_norm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>3</td>\n",
       "      <td>15</td>\n",
       "      <td>0.202763</td>\n",
       "      <td>0.922917</td>\n",
       "      <td>10.710969</td>\n",
       "      <td>165.910115</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1000</td>\n",
       "      <td>1</td>\n",
       "      <td>cuda</td>\n",
       "      <td>normal</td>\n",
       "      <td>no_batch_norm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>2</td>\n",
       "      <td>12</td>\n",
       "      <td>0.208459</td>\n",
       "      <td>0.922667</td>\n",
       "      <td>7.040456</td>\n",
       "      <td>93.766507</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1000</td>\n",
       "      <td>1</td>\n",
       "      <td>cuda</td>\n",
       "      <td>not_normal</td>\n",
       "      <td>batch_norm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>3</td>\n",
       "      <td>14</td>\n",
       "      <td>0.204546</td>\n",
       "      <td>0.922200</td>\n",
       "      <td>9.795749</td>\n",
       "      <td>155.066447</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1000</td>\n",
       "      <td>1</td>\n",
       "      <td>cuda</td>\n",
       "      <td>normal</td>\n",
       "      <td>no_batch_norm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>2</td>\n",
       "      <td>11</td>\n",
       "      <td>0.211542</td>\n",
       "      <td>0.921633</td>\n",
       "      <td>6.744750</td>\n",
       "      <td>86.535944</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1000</td>\n",
       "      <td>1</td>\n",
       "      <td>cuda</td>\n",
       "      <td>not_normal</td>\n",
       "      <td>batch_norm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>3</td>\n",
       "      <td>18</td>\n",
       "      <td>0.207138</td>\n",
       "      <td>0.921333</td>\n",
       "      <td>10.047941</td>\n",
       "      <td>197.258564</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1000</td>\n",
       "      <td>1</td>\n",
       "      <td>cuda</td>\n",
       "      <td>normal</td>\n",
       "      <td>no_batch_norm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>3</td>\n",
       "      <td>11</td>\n",
       "      <td>0.209746</td>\n",
       "      <td>0.921150</td>\n",
       "      <td>10.306909</td>\n",
       "      <td>120.070154</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1000</td>\n",
       "      <td>1</td>\n",
       "      <td>cuda</td>\n",
       "      <td>normal</td>\n",
       "      <td>no_batch_norm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0.211247</td>\n",
       "      <td>0.921083</td>\n",
       "      <td>10.310635</td>\n",
       "      <td>109.569371</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1000</td>\n",
       "      <td>1</td>\n",
       "      <td>cuda</td>\n",
       "      <td>normal</td>\n",
       "      <td>no_batch_norm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>3</td>\n",
       "      <td>20</td>\n",
       "      <td>0.208982</td>\n",
       "      <td>0.919700</td>\n",
       "      <td>10.855825</td>\n",
       "      <td>218.407750</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1000</td>\n",
       "      <td>1</td>\n",
       "      <td>cuda</td>\n",
       "      <td>normal</td>\n",
       "      <td>no_batch_norm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>0.215449</td>\n",
       "      <td>0.919067</td>\n",
       "      <td>10.820235</td>\n",
       "      <td>99.104830</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1000</td>\n",
       "      <td>1</td>\n",
       "      <td>cuda</td>\n",
       "      <td>normal</td>\n",
       "      <td>no_batch_norm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>3</td>\n",
       "      <td>19</td>\n",
       "      <td>0.214903</td>\n",
       "      <td>0.918483</td>\n",
       "      <td>9.968742</td>\n",
       "      <td>207.409789</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1000</td>\n",
       "      <td>1</td>\n",
       "      <td>cuda</td>\n",
       "      <td>normal</td>\n",
       "      <td>no_batch_norm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>0.220037</td>\n",
       "      <td>0.916617</td>\n",
       "      <td>10.156970</td>\n",
       "      <td>88.162933</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1000</td>\n",
       "      <td>1</td>\n",
       "      <td>cuda</td>\n",
       "      <td>normal</td>\n",
       "      <td>no_batch_norm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.222170</td>\n",
       "      <td>0.916117</td>\n",
       "      <td>7.605935</td>\n",
       "      <td>79.687478</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1000</td>\n",
       "      <td>1</td>\n",
       "      <td>cuda</td>\n",
       "      <td>not_normal</td>\n",
       "      <td>batch_norm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>0.223663</td>\n",
       "      <td>0.916033</td>\n",
       "      <td>10.278862</td>\n",
       "      <td>77.777741</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1000</td>\n",
       "      <td>1</td>\n",
       "      <td>cuda</td>\n",
       "      <td>normal</td>\n",
       "      <td>no_batch_norm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>0.228389</td>\n",
       "      <td>0.914617</td>\n",
       "      <td>7.617868</td>\n",
       "      <td>71.891108</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1000</td>\n",
       "      <td>1</td>\n",
       "      <td>cuda</td>\n",
       "      <td>not_normal</td>\n",
       "      <td>batch_norm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>0.229496</td>\n",
       "      <td>0.913583</td>\n",
       "      <td>10.892500</td>\n",
       "      <td>67.360719</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1000</td>\n",
       "      <td>1</td>\n",
       "      <td>cuda</td>\n",
       "      <td>normal</td>\n",
       "      <td>no_batch_norm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>0.237451</td>\n",
       "      <td>0.911750</td>\n",
       "      <td>7.575090</td>\n",
       "      <td>64.147059</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1000</td>\n",
       "      <td>1</td>\n",
       "      <td>cuda</td>\n",
       "      <td>not_normal</td>\n",
       "      <td>batch_norm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>0.239245</td>\n",
       "      <td>0.911267</td>\n",
       "      <td>10.514680</td>\n",
       "      <td>56.334251</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1000</td>\n",
       "      <td>1</td>\n",
       "      <td>cuda</td>\n",
       "      <td>normal</td>\n",
       "      <td>no_batch_norm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0.245825</td>\n",
       "      <td>0.909833</td>\n",
       "      <td>9.675661</td>\n",
       "      <td>11.754569</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1000</td>\n",
       "      <td>1</td>\n",
       "      <td>cuda</td>\n",
       "      <td>normal</td>\n",
       "      <td>batch_norm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>0.244662</td>\n",
       "      <td>0.908667</td>\n",
       "      <td>7.400404</td>\n",
       "      <td>56.386718</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1000</td>\n",
       "      <td>1</td>\n",
       "      <td>cuda</td>\n",
       "      <td>not_normal</td>\n",
       "      <td>batch_norm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>0.249748</td>\n",
       "      <td>0.906783</td>\n",
       "      <td>10.980170</td>\n",
       "      <td>45.657420</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1000</td>\n",
       "      <td>1</td>\n",
       "      <td>cuda</td>\n",
       "      <td>normal</td>\n",
       "      <td>no_batch_norm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "      <td>0.248386</td>\n",
       "      <td>0.906283</td>\n",
       "      <td>7.565741</td>\n",
       "      <td>154.781898</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1000</td>\n",
       "      <td>1</td>\n",
       "      <td>cuda</td>\n",
       "      <td>not_normal</td>\n",
       "      <td>no_batch_norm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "      <td>0.253798</td>\n",
       "      <td>0.905967</td>\n",
       "      <td>7.967798</td>\n",
       "      <td>126.451212</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1000</td>\n",
       "      <td>1</td>\n",
       "      <td>cuda</td>\n",
       "      <td>not_normal</td>\n",
       "      <td>no_batch_norm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1</td>\n",
       "      <td>19</td>\n",
       "      <td>0.251073</td>\n",
       "      <td>0.905717</td>\n",
       "      <td>5.981989</td>\n",
       "      <td>147.089327</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1000</td>\n",
       "      <td>1</td>\n",
       "      <td>cuda</td>\n",
       "      <td>not_normal</td>\n",
       "      <td>no_batch_norm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1</td>\n",
       "      <td>18</td>\n",
       "      <td>0.252614</td>\n",
       "      <td>0.905083</td>\n",
       "      <td>6.958172</td>\n",
       "      <td>140.960084</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1000</td>\n",
       "      <td>1</td>\n",
       "      <td>cuda</td>\n",
       "      <td>not_normal</td>\n",
       "      <td>no_batch_norm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>0.257936</td>\n",
       "      <td>0.904800</td>\n",
       "      <td>7.329757</td>\n",
       "      <td>118.309068</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1000</td>\n",
       "      <td>1</td>\n",
       "      <td>cuda</td>\n",
       "      <td>not_normal</td>\n",
       "      <td>no_batch_norm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "      <td>0.255311</td>\n",
       "      <td>0.904500</td>\n",
       "      <td>7.250519</td>\n",
       "      <td>133.831426</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1000</td>\n",
       "      <td>1</td>\n",
       "      <td>cuda</td>\n",
       "      <td>not_normal</td>\n",
       "      <td>no_batch_norm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>0.259576</td>\n",
       "      <td>0.903500</td>\n",
       "      <td>8.338075</td>\n",
       "      <td>48.842084</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1000</td>\n",
       "      <td>1</td>\n",
       "      <td>cuda</td>\n",
       "      <td>not_normal</td>\n",
       "      <td>batch_norm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0.263221</td>\n",
       "      <td>0.902483</td>\n",
       "      <td>10.547528</td>\n",
       "      <td>34.497680</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1000</td>\n",
       "      <td>1</td>\n",
       "      <td>cuda</td>\n",
       "      <td>normal</td>\n",
       "      <td>no_batch_norm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "      <td>0.265899</td>\n",
       "      <td>0.901550</td>\n",
       "      <td>7.090938</td>\n",
       "      <td>110.887263</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1000</td>\n",
       "      <td>1</td>\n",
       "      <td>cuda</td>\n",
       "      <td>not_normal</td>\n",
       "      <td>no_batch_norm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>0.270913</td>\n",
       "      <td>0.899950</td>\n",
       "      <td>7.412771</td>\n",
       "      <td>103.675098</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1000</td>\n",
       "      <td>1</td>\n",
       "      <td>cuda</td>\n",
       "      <td>not_normal</td>\n",
       "      <td>no_batch_norm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>0.269132</td>\n",
       "      <td>0.899050</td>\n",
       "      <td>8.171682</td>\n",
       "      <td>40.340225</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1000</td>\n",
       "      <td>1</td>\n",
       "      <td>cuda</td>\n",
       "      <td>not_normal</td>\n",
       "      <td>batch_norm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>0.278508</td>\n",
       "      <td>0.896617</td>\n",
       "      <td>6.911745</td>\n",
       "      <td>96.166525</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1000</td>\n",
       "      <td>1</td>\n",
       "      <td>cuda</td>\n",
       "      <td>not_normal</td>\n",
       "      <td>no_batch_norm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>0.286149</td>\n",
       "      <td>0.893817</td>\n",
       "      <td>7.647107</td>\n",
       "      <td>89.087022</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1000</td>\n",
       "      <td>1</td>\n",
       "      <td>cuda</td>\n",
       "      <td>not_normal</td>\n",
       "      <td>no_batch_norm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0.293104</td>\n",
       "      <td>0.893467</td>\n",
       "      <td>10.265260</td>\n",
       "      <td>23.774091</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1000</td>\n",
       "      <td>1</td>\n",
       "      <td>cuda</td>\n",
       "      <td>normal</td>\n",
       "      <td>no_batch_norm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>0.286496</td>\n",
       "      <td>0.892017</td>\n",
       "      <td>8.133780</td>\n",
       "      <td>32.004773</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1000</td>\n",
       "      <td>1</td>\n",
       "      <td>cuda</td>\n",
       "      <td>not_normal</td>\n",
       "      <td>batch_norm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>0.297853</td>\n",
       "      <td>0.889417</td>\n",
       "      <td>7.637054</td>\n",
       "      <td>81.318339</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1000</td>\n",
       "      <td>1</td>\n",
       "      <td>cuda</td>\n",
       "      <td>not_normal</td>\n",
       "      <td>no_batch_norm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>0.306117</td>\n",
       "      <td>0.886667</td>\n",
       "      <td>7.888400</td>\n",
       "      <td>73.559744</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1000</td>\n",
       "      <td>1</td>\n",
       "      <td>cuda</td>\n",
       "      <td>not_normal</td>\n",
       "      <td>no_batch_norm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0.306475</td>\n",
       "      <td>0.885317</td>\n",
       "      <td>6.764283</td>\n",
       "      <td>23.742105</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1000</td>\n",
       "      <td>1</td>\n",
       "      <td>cuda</td>\n",
       "      <td>not_normal</td>\n",
       "      <td>batch_norm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>0.319635</td>\n",
       "      <td>0.881883</td>\n",
       "      <td>7.377742</td>\n",
       "      <td>65.512631</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1000</td>\n",
       "      <td>1</td>\n",
       "      <td>cuda</td>\n",
       "      <td>not_normal</td>\n",
       "      <td>no_batch_norm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>0.336331</td>\n",
       "      <td>0.876117</td>\n",
       "      <td>7.576496</td>\n",
       "      <td>58.029267</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1000</td>\n",
       "      <td>1</td>\n",
       "      <td>cuda</td>\n",
       "      <td>not_normal</td>\n",
       "      <td>no_batch_norm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.343547</td>\n",
       "      <td>0.872567</td>\n",
       "      <td>7.246636</td>\n",
       "      <td>16.806404</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1000</td>\n",
       "      <td>1</td>\n",
       "      <td>cuda</td>\n",
       "      <td>not_normal</td>\n",
       "      <td>batch_norm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>0.352988</td>\n",
       "      <td>0.869767</td>\n",
       "      <td>7.403024</td>\n",
       "      <td>50.345708</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1000</td>\n",
       "      <td>1</td>\n",
       "      <td>cuda</td>\n",
       "      <td>not_normal</td>\n",
       "      <td>no_batch_norm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0.374156</td>\n",
       "      <td>0.862267</td>\n",
       "      <td>7.476776</td>\n",
       "      <td>42.786971</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1000</td>\n",
       "      <td>1</td>\n",
       "      <td>cuda</td>\n",
       "      <td>not_normal</td>\n",
       "      <td>no_batch_norm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0.579350</td>\n",
       "      <td>0.851817</td>\n",
       "      <td>10.738461</td>\n",
       "      <td>13.372497</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1000</td>\n",
       "      <td>1</td>\n",
       "      <td>cuda</td>\n",
       "      <td>normal</td>\n",
       "      <td>no_batch_norm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0.411397</td>\n",
       "      <td>0.849217</td>\n",
       "      <td>7.194037</td>\n",
       "      <td>35.216199</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1000</td>\n",
       "      <td>1</td>\n",
       "      <td>cuda</td>\n",
       "      <td>not_normal</td>\n",
       "      <td>no_batch_norm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0.465293</td>\n",
       "      <td>0.828217</td>\n",
       "      <td>6.844383</td>\n",
       "      <td>27.916469</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1000</td>\n",
       "      <td>1</td>\n",
       "      <td>cuda</td>\n",
       "      <td>not_normal</td>\n",
       "      <td>no_batch_norm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.573569</td>\n",
       "      <td>0.791250</td>\n",
       "      <td>6.879652</td>\n",
       "      <td>9.384482</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1000</td>\n",
       "      <td>1</td>\n",
       "      <td>cuda</td>\n",
       "      <td>not_normal</td>\n",
       "      <td>batch_norm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.545249</td>\n",
       "      <td>0.788833</td>\n",
       "      <td>7.605963</td>\n",
       "      <td>20.910635</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1000</td>\n",
       "      <td>1</td>\n",
       "      <td>cuda</td>\n",
       "      <td>not_normal</td>\n",
       "      <td>no_batch_norm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.010034</td>\n",
       "      <td>0.606967</td>\n",
       "      <td>7.325416</td>\n",
       "      <td>13.160287</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1000</td>\n",
       "      <td>1</td>\n",
       "      <td>cuda</td>\n",
       "      <td>not_normal</td>\n",
       "      <td>no_batch_norm</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    run  epoch      loss  accuracy  epoch duration  run duration    lr  \\\n",
       "79    4     20  0.110408  0.957317       10.035356    205.923431  0.01   \n",
       "78    4     19  0.115360  0.955300        9.918997    195.681020  0.01   \n",
       "77    4     18  0.115337  0.955033        9.984033    185.624281  0.01   \n",
       "76    4     17  0.120762  0.952700       10.230132    175.442173  0.01   \n",
       "75    4     16  0.125689  0.952133        9.969344    165.065828  0.01   \n",
       "74    4     15  0.137869  0.948017       10.467396    154.903531  0.01   \n",
       "73    4     14  0.139621  0.946200        9.497421    144.227819  0.01   \n",
       "72    4     13  0.145431  0.944733       10.374502    134.604298  0.01   \n",
       "71    4     12  0.146747  0.943683       10.059436    124.028419  0.01   \n",
       "70    4     11  0.155680  0.940317        9.997989    113.749509  0.01   \n",
       "69    4     10  0.156015  0.939800        9.583233    103.621759  0.01   \n",
       "67    4      8  0.156590  0.939717        9.703273     83.628218  0.01   \n",
       "64    4      5  0.160415  0.939133       10.417717     54.451969  0.01   \n",
       "66    4      7  0.158894  0.939100        9.588355     73.804569  0.01   \n",
       "68    4      9  0.157441  0.938900        9.986464     93.843158  0.01   \n",
       "63    4      4  0.163364  0.938767       10.337799     43.889219  0.01   \n",
       "65    4      6  0.161548  0.938150        9.394383     64.040888  0.01   \n",
       "39    2     20  0.167247  0.936067        7.775005    153.603966  0.01   \n",
       "37    2     18  0.173398  0.934700        7.604895    137.686313  0.01   \n",
       "62    4      3  0.174762  0.934300       10.017647     33.436595  0.01   \n",
       "38    2     19  0.172948  0.934200        7.745587    145.652274  0.01   \n",
       "35    2     16  0.180939  0.932733        6.491221    122.115530  0.01   \n",
       "36    2     17  0.177467  0.932600        7.612194    129.885850  0.01   \n",
       "34    2     15  0.183518  0.931867        7.085083    115.425863  0.01   \n",
       "33    2     14  0.193205  0.927983        7.124583    108.196270  0.01   \n",
       "61    4      2  0.190643  0.927733       11.381498     23.290640  0.01   \n",
       "32    2     13  0.201877  0.924533        7.009605    100.900473  0.01   \n",
       "56    3     17  0.203397  0.924133       10.665856    187.003731  0.01   \n",
       "55    3     16  0.202173  0.924033       10.102604    176.150221  0.01   \n",
       "52    3     13  0.202723  0.923917        9.909368    145.100881  0.01   \n",
       "51    3     12  0.205129  0.923767       14.789005    135.029758  0.01   \n",
       "54    3     15  0.202763  0.922917       10.710969    165.910115  0.01   \n",
       "31    2     12  0.208459  0.922667        7.040456     93.766507  0.01   \n",
       "53    3     14  0.204546  0.922200        9.795749    155.066447  0.01   \n",
       "30    2     11  0.211542  0.921633        6.744750     86.535944  0.01   \n",
       "57    3     18  0.207138  0.921333       10.047941    197.258564  0.01   \n",
       "50    3     11  0.209746  0.921150       10.306909    120.070154  0.01   \n",
       "49    3     10  0.211247  0.921083       10.310635    109.569371  0.01   \n",
       "59    3     20  0.208982  0.919700       10.855825    218.407750  0.01   \n",
       "48    3      9  0.215449  0.919067       10.820235     99.104830  0.01   \n",
       "58    3     19  0.214903  0.918483        9.968742    207.409789  0.01   \n",
       "47    3      8  0.220037  0.916617       10.156970     88.162933  0.01   \n",
       "29    2     10  0.222170  0.916117        7.605935     79.687478  0.01   \n",
       "46    3      7  0.223663  0.916033       10.278862     77.777741  0.01   \n",
       "28    2      9  0.228389  0.914617        7.617868     71.891108  0.01   \n",
       "45    3      6  0.229496  0.913583       10.892500     67.360719  0.01   \n",
       "27    2      8  0.237451  0.911750        7.575090     64.147059  0.01   \n",
       "44    3      5  0.239245  0.911267       10.514680     56.334251  0.01   \n",
       "60    4      1  0.245825  0.909833        9.675661     11.754569  0.01   \n",
       "26    2      7  0.244662  0.908667        7.400404     56.386718  0.01   \n",
       "43    3      4  0.249748  0.906783       10.980170     45.657420  0.01   \n",
       "19    1     20  0.248386  0.906283        7.565741    154.781898  0.01   \n",
       "15    1     16  0.253798  0.905967        7.967798    126.451212  0.01   \n",
       "18    1     19  0.251073  0.905717        5.981989    147.089327  0.01   \n",
       "17    1     18  0.252614  0.905083        6.958172    140.960084  0.01   \n",
       "14    1     15  0.257936  0.904800        7.329757    118.309068  0.01   \n",
       "16    1     17  0.255311  0.904500        7.250519    133.831426  0.01   \n",
       "25    2      6  0.259576  0.903500        8.338075     48.842084  0.01   \n",
       "42    3      3  0.263221  0.902483       10.547528     34.497680  0.01   \n",
       "13    1     14  0.265899  0.901550        7.090938    110.887263  0.01   \n",
       "12    1     13  0.270913  0.899950        7.412771    103.675098  0.01   \n",
       "24    2      5  0.269132  0.899050        8.171682     40.340225  0.01   \n",
       "11    1     12  0.278508  0.896617        6.911745     96.166525  0.01   \n",
       "10    1     11  0.286149  0.893817        7.647107     89.087022  0.01   \n",
       "41    3      2  0.293104  0.893467       10.265260     23.774091  0.01   \n",
       "23    2      4  0.286496  0.892017        8.133780     32.004773  0.01   \n",
       "9     1     10  0.297853  0.889417        7.637054     81.318339  0.01   \n",
       "8     1      9  0.306117  0.886667        7.888400     73.559744  0.01   \n",
       "22    2      3  0.306475  0.885317        6.764283     23.742105  0.01   \n",
       "7     1      8  0.319635  0.881883        7.377742     65.512631  0.01   \n",
       "6     1      7  0.336331  0.876117        7.576496     58.029267  0.01   \n",
       "21    2      2  0.343547  0.872567        7.246636     16.806404  0.01   \n",
       "5     1      6  0.352988  0.869767        7.403024     50.345708  0.01   \n",
       "4     1      5  0.374156  0.862267        7.476776     42.786971  0.01   \n",
       "40    3      1  0.579350  0.851817       10.738461     13.372497  0.01   \n",
       "3     1      4  0.411397  0.849217        7.194037     35.216199  0.01   \n",
       "2     1      3  0.465293  0.828217        6.844383     27.916469  0.01   \n",
       "20    2      1  0.573569  0.791250        6.879652      9.384482  0.01   \n",
       "1     1      2  0.545249  0.788833        7.605963     20.910635  0.01   \n",
       "0     1      1  1.010034  0.606967        7.325416     13.160287  0.01   \n",
       "\n",
       "    batch_size  num_workers device    trainset        network  \n",
       "79        1000            1   cuda      normal     batch_norm  \n",
       "78        1000            1   cuda      normal     batch_norm  \n",
       "77        1000            1   cuda      normal     batch_norm  \n",
       "76        1000            1   cuda      normal     batch_norm  \n",
       "75        1000            1   cuda      normal     batch_norm  \n",
       "74        1000            1   cuda      normal     batch_norm  \n",
       "73        1000            1   cuda      normal     batch_norm  \n",
       "72        1000            1   cuda      normal     batch_norm  \n",
       "71        1000            1   cuda      normal     batch_norm  \n",
       "70        1000            1   cuda      normal     batch_norm  \n",
       "69        1000            1   cuda      normal     batch_norm  \n",
       "67        1000            1   cuda      normal     batch_norm  \n",
       "64        1000            1   cuda      normal     batch_norm  \n",
       "66        1000            1   cuda      normal     batch_norm  \n",
       "68        1000            1   cuda      normal     batch_norm  \n",
       "63        1000            1   cuda      normal     batch_norm  \n",
       "65        1000            1   cuda      normal     batch_norm  \n",
       "39        1000            1   cuda  not_normal     batch_norm  \n",
       "37        1000            1   cuda  not_normal     batch_norm  \n",
       "62        1000            1   cuda      normal     batch_norm  \n",
       "38        1000            1   cuda  not_normal     batch_norm  \n",
       "35        1000            1   cuda  not_normal     batch_norm  \n",
       "36        1000            1   cuda  not_normal     batch_norm  \n",
       "34        1000            1   cuda  not_normal     batch_norm  \n",
       "33        1000            1   cuda  not_normal     batch_norm  \n",
       "61        1000            1   cuda      normal     batch_norm  \n",
       "32        1000            1   cuda  not_normal     batch_norm  \n",
       "56        1000            1   cuda      normal  no_batch_norm  \n",
       "55        1000            1   cuda      normal  no_batch_norm  \n",
       "52        1000            1   cuda      normal  no_batch_norm  \n",
       "51        1000            1   cuda      normal  no_batch_norm  \n",
       "54        1000            1   cuda      normal  no_batch_norm  \n",
       "31        1000            1   cuda  not_normal     batch_norm  \n",
       "53        1000            1   cuda      normal  no_batch_norm  \n",
       "30        1000            1   cuda  not_normal     batch_norm  \n",
       "57        1000            1   cuda      normal  no_batch_norm  \n",
       "50        1000            1   cuda      normal  no_batch_norm  \n",
       "49        1000            1   cuda      normal  no_batch_norm  \n",
       "59        1000            1   cuda      normal  no_batch_norm  \n",
       "48        1000            1   cuda      normal  no_batch_norm  \n",
       "58        1000            1   cuda      normal  no_batch_norm  \n",
       "47        1000            1   cuda      normal  no_batch_norm  \n",
       "29        1000            1   cuda  not_normal     batch_norm  \n",
       "46        1000            1   cuda      normal  no_batch_norm  \n",
       "28        1000            1   cuda  not_normal     batch_norm  \n",
       "45        1000            1   cuda      normal  no_batch_norm  \n",
       "27        1000            1   cuda  not_normal     batch_norm  \n",
       "44        1000            1   cuda      normal  no_batch_norm  \n",
       "60        1000            1   cuda      normal     batch_norm  \n",
       "26        1000            1   cuda  not_normal     batch_norm  \n",
       "43        1000            1   cuda      normal  no_batch_norm  \n",
       "19        1000            1   cuda  not_normal  no_batch_norm  \n",
       "15        1000            1   cuda  not_normal  no_batch_norm  \n",
       "18        1000            1   cuda  not_normal  no_batch_norm  \n",
       "17        1000            1   cuda  not_normal  no_batch_norm  \n",
       "14        1000            1   cuda  not_normal  no_batch_norm  \n",
       "16        1000            1   cuda  not_normal  no_batch_norm  \n",
       "25        1000            1   cuda  not_normal     batch_norm  \n",
       "42        1000            1   cuda      normal  no_batch_norm  \n",
       "13        1000            1   cuda  not_normal  no_batch_norm  \n",
       "12        1000            1   cuda  not_normal  no_batch_norm  \n",
       "24        1000            1   cuda  not_normal     batch_norm  \n",
       "11        1000            1   cuda  not_normal  no_batch_norm  \n",
       "10        1000            1   cuda  not_normal  no_batch_norm  \n",
       "41        1000            1   cuda      normal  no_batch_norm  \n",
       "23        1000            1   cuda  not_normal     batch_norm  \n",
       "9         1000            1   cuda  not_normal  no_batch_norm  \n",
       "8         1000            1   cuda  not_normal  no_batch_norm  \n",
       "22        1000            1   cuda  not_normal     batch_norm  \n",
       "7         1000            1   cuda  not_normal  no_batch_norm  \n",
       "6         1000            1   cuda  not_normal  no_batch_norm  \n",
       "21        1000            1   cuda  not_normal     batch_norm  \n",
       "5         1000            1   cuda  not_normal  no_batch_norm  \n",
       "4         1000            1   cuda  not_normal  no_batch_norm  \n",
       "40        1000            1   cuda      normal  no_batch_norm  \n",
       "3         1000            1   cuda  not_normal  no_batch_norm  \n",
       "2         1000            1   cuda  not_normal  no_batch_norm  \n",
       "20        1000            1   cuda  not_normal     batch_norm  \n",
       "1         1000            1   cuda  not_normal  no_batch_norm  \n",
       "0         1000            1   cuda  not_normal  no_batch_norm  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame.from_dict(m.run_data,orient='columns').sort_values('accuracy',ascending=False) #dit zorgt dat het in een leuk tabelletje staat\n",
    "pd.set_option('display.max_rows',None)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
